\documentclass[11.5pt,a4paper]{article}

\setlength{\topmargin}{0cm}
\setlength{\headheight}{0.4cm}
\setlength{\headsep}{0.8cm}
\setlength{\footskip}{1cm}
\setlength{\textwidth}{17cm}
\setlength{\textheight}{25cm}
\setlength{\voffset}{-1.5cm}
\setlength{\hoffset}{-0.5cm}
\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{0cm}

\usepackage{graphicx} % inclusion des figures
\usepackage{amsmath} % collection de symboles math�matiques
\usepackage{amssymb} % collection de symboles math�matiques
%\usepackage{subfigure} % 2 Bilder nebeneinander
\usepackage{placeins} %FloatBarrier
\usepackage{mathtools} % align in matrix

%\usepackage[applemac]{inputenc} % utilisation directe des caract�res accentu�s sur mac
%\usepackage[latin1]{inputenc}   % utilisation directe des caract�res accentu�s sur pc
\usepackage[ansinew]{inputenc}	 % klappt unter windows

\usepackage[german,ngerman, english]{babel} %% Deutsch als Hauptsprache
%\usepackage{epstopdf} % wandelt eps-dateien in pdf-datein um
\usepackage[T1]{fontenc} % codage moderne des caract�res sous Latex

\usepackage{tabularx} % Tabellen mit variabler Spaltenbreite

\usepackage{color} % gestion de diff�rentes couleurs
\definecolor{linkcolor}{rgb}{0,0,0.6} % d�finition de la couleur des liens pdf
\usepackage[ pdftex,colorlinks=true, pdfstartview=FitV,
linkcolor= linkcolor, citecolor= linkcolor, urlcolor= linkcolor,
hyperindex=true, hyperfigures=false]{hyperref} % fichiers pdf 'intelligents', avec des liens entre les r�f�rences, etc.

\usepackage{fancyhdr} % Wahl der Kopf- und Fu�zeile
\pagestyle{headings} %zeigt Seitennummer und Abschnittstitel an
\usepackage{fancyvrb}
\VerbatimFootnotes %Verbatim in Footnotes

\usepackage[center]{caption}

\usepackage{graphicx}
\usepackage{subcaption}

%\pagestyle{fancy} %manuelle Wahl der Kopf- und Fu�zeile
%\fancyhead[L]{\scriptsize \textsc{Electrical properties of a Carbon Nanotube device under extreme conditions}}
%\fancyhead[R]{\scriptsize \textsc{Mario Bomers}}
%\fancyfoot[C]{ \thepage}

\usepackage[normalem]{ulem}
\usepackage{moreverb}
\usepackage{color}
\usepackage{listings} %code listings
\usepackage{verbatim} %multiline comments
\usepackage{color}
 
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{ %
  language=Matlab,                % the language of the code
  basicstyle=\footnotesize,           % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it's 1, each line 
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},      % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  %captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  %title=\lstname,                   % show the filename of files included with \lstinputlisting;
                                  % also try caption instead of title
  keywordstyle=\color{blue},          % keyword style
  commentstyle=\color{dkgreen},       % comment style
  stringstyle=\color{mauve},         % string literal style
  escapeinside={\%*}{*)},            % if you want to add LaTeX within your code
  morekeywords={*,...}               % if you want to add more keywords to the set
}



\begin{document}

\setlength{\parindent}{0pt} %kein Einzug bei neuen Abschnitten

%-------------------------------	Deckblatt		-----------------------------

\thispagestyle{empty}

\includegraphics[height=2cm]{FULogo.jpg}
\hfill %\hfill wird das "a" am linken Seitenrand, "b" am rechten Seitenrand angeordnet ("a" \hfill "b")
\parbox[b]{0.5\textwidth}{{\large Bachelorarbeit Juli 2012\\}}

\vspace{2cm}

\begin{center}

\rule[11pt]{15cm}{0.5pt}

{ \textbf {\Large Large Scale Parallel Simulation of EPR Lineshape Spectra}}

\rule{15cm}{0.5pt}

\vspace{1cm}

\parbox{15cm}{\small
\textbf{Abstract}: \emph{Electron Paramagnetic Resonance} is a spectroscopy method to investigate systems of unpaired electron spins. \emph{Spinach} is a Matlab library to simulate different kinds of spin system experiemnts, including EPR. This paper aims to give an overview of the theoretical concepts involved in spin dynamics, especially those necessary to comprehend  Spinach's way of numerical computation. After understanding the parameters determining Spinach's resources usage we adopt parallel computing methods on Linux clusters to accelerate the calculation of EPR lineshape spectra.  }

\vspace{0.5cm}

\end{center}

\vspace{1cm}

\large{

{\bf Author:}  Johannes H\"ormann}
\vspace{0.3cm}

{\bf Supervisor:} Hossam Elgabarty

\vspace{1cm}

%\begin{figure}[h!]
%	\centering
%	\includegraphics[width=0.6\textwidth]{screenshot1-546nm.jpg}
%	\caption{Fabry-Perot fringes of 546nm line, no magnetic influence}
%	\label{fringes-546nm}
%\end{figure}

%\newpage
\tableofcontents

\vfill
\hfill \today 

%------------------------------------------------------------

\newpage

\section{Theory of $\tfrac{\pi}{2}$-pulsed EPR}
\subsection{Introduction}
The mechanisms of \emph{EPR (Electron Paramegnetic Resonance)}, also called \emph{ESR (Electron Spin Resonance)}, work analogous to the mechanisms of \emph{NMR (Nuclear Magnetic Resonance)}. In \emph{diamagnetic} materials, all electrons are spin-paired, making the elctron magnetic dipole vanish, and enabling the system to be accessible by NMR. 
%, and according to \cite[Chap. 4, p. 107]{nmr-ox}, NMR technique offer two further ``advantages'' in comparison with EPR: First, relaxation time of spin electrons is very short compared with nuclei; second the nuclear spin Hamiltonian offers a broader diversity of interactions giving insight to the system's properties. Nevertheless, 
EPR experiments are suitable to investigate \emph{paramagnetic} systems with unpaired electron spins, which exhibit a non-zero electron spin. The basic idea is to perturb a spin system's equilibrium by a small pulsed oscillating magnetic field:

When we place a \emph{powder sample} of spin sytems inside a static magnetic field $\vec{B}_0 = B_0 \hat{z}$ and let it settle to equilibrium, due to Zeeman effect more electron spins are goint to align parallel to $\vec{B}_0$ than antiparallel, resulting in a net magnetization of the sample. When speaking of a powder sample we mean a sample in which many spin systems exist in randomly distributed spatial orientations. A magnetic pulse $\vec{B}_1(t) = B_1(t) \hat{x}$ linearly polarized in x-direction will tilt the electron spins and disturb the equilibrium in a way we are going to examine in the course of this article. The resulting time-dependent magnetization during the relaxation process may be recorded. This time-resolved signal is called the \emph{free induction decay (FID)}. 
%The pulse $\vec{B}_1 = B_1 \hat{x} e^{i(\vec{k}\cdot\vec{r}-\omega_1 t)} \cdot u(t_0-t)$ linearly polarized in x-direction will tilt the electron spins and disturb the equilibrium in a way we are going to examine in the course of this article.

\subsection{Spin interactions}
\subsubsection{Spin system Hamiltonian}
Like in any other quantum mechanical problem the starting point when treating an EPR experiment theoretically is the Schr\"odinger equation\footnote{Following spin dynamics conventions in the course of this article we set $\hbar = 1$}
\begin{equation}
 i \hbar \frac{\partial}{\partial t} |\psi\rangle = \mathcal{H} |\psi \rangle
\end{equation}
 For a start we examine the Hamiltonion of an unpaired spin electron system in a static magnetic field. It will exhibit several perturbation terms of different nature:
\begin{equation}
 \mathcal{H} = \left[\mathcal{H}_{EZ} + \mathcal{H}_{ECS} + \mathcal{H}_{LS}\right] + \left[\mathcal{H}_{HF}\right] + \left[\mathcal{H}_{NZ} + \mathcal{H}_{NCS} + \text{weaker interactions}\right]
\end{equation}
\begin{enumerate}
  \item \uline{Electron Zeeman contribution} $\mathcal{H}_{EZ} = - \vec{\mu} \cdot \vec{B}_0 = -\hbar B_0 (\gamma_L \mathbf{L}_z + \gamma_S \mathbf{S}_z)$

  The static magnetic field $\vec{B}_0 = B_0 \hat{z}$ acts a torque on the electron's magnetic dipole moment $\mu$, linearly dependent on its angular momentum and spin. Thus the \emph{Zeeman effect} lifts the spin degeneracy of energy levels, reducing the energy of spins aligned parallel to the magnetic field (-), and increasing the energy of spins aligned antiparallel (+) by the correction term\footnote{for a thorought derivation of the energy correction term see \cite[chap. 6.4 The Zeeman Effect, p. 277ff]{griffiths}}
  \begin{equation}
   E^1_\pm = \pm \mu_B \gamma_J B_0 m_J 
  \end{equation}
  
 % Boltzmann statistics yields the relation for the equilibrium occupancy of states
 % \begin{equation}
 %   \frac{N_+}{N_-} = e^{- \frac{\Delta E}{k_B T}}
 % \end{equation}

  \item \uline{Electron chemical shift} $\mathcal{H}_{ECS} = \gamma_S \hbar \mathbf{S} \cdot \sigma_S(t) \cdot \vec{B}_0$
  
  The moving electron clouds change the effective magnetic field $\vec{B}_\text{eff}$ ``seen'' by the every electron spin. This ``shielding'' behaviour is desctribed by the \emph{chemical shift tensor} $\sigma_S(t)$:
  \begin{equation}
    \vec{B}_\text{eff}(t) = - \sigma_S(t) \cdot \vec{B}_0
  \end{equation}

  \item \uline{Spin-orbit coupling} $\mathcal{H}_{LS} = \lambda \mathbf{L}\cdot \mathbf{S}$

  The electron's motion around the nucleus creates a magnetic field, with which the electron's spin will interact. 
  Together with the Zeeman interaction, those two Hamiltonian contributions are due to the influence of a magnetic field. Furthermore, the externam Zeeman field causes $\vec{L}$ to change, thus also influencing the spin-orbit interaction.

  \item \uline{Hyperfine interaction} $\mathcal{H}_{HF} = \frac{\gamma_I \gamma_S \hbar^2}{r^3} \left[ \frac{3 (\mathbf{I} \cdot \vec{r}(t) ) (\mathbf{S} \cdot \vec{r}(t) )}{r^2} - \mathbf{I} \cdot \mathbf{S} \right]$
   
  The nucleus interacts with the orbiting electron due to the electron's induced magnetic field acting on the nuclear magnetic dipole moment. 

  \item \uline{Nuclear Zeeman contribution} $\mathcal{H}_{NZ} = -\hbar B_0 \gamma_I \mathbf{I}_z$
  
  Just like the electron, the nucleus posseses intrinsic spin and thus a nuclear magnetic moment, enabling it to interact with an external magnetic field.

  \item \uline{Nuclear chemical shift} $\mathcal{H}_{NCS} = \gamma_I \hbar \mathbf{I} \cdot \sigma_I(t) \cdot \vec{B}_0$
  
  Of course, the shielding by the electron clouds also applies to the nuclei's spins $\mathbf{I}$.
  \begin{equation}
    \vec{B}_\text{eff}(t) = - \sigma_I(t) \cdot \vec{B}_0
  \end{equation}

  \item \uline{Other weaker interactions} like coupling of the nuclear quadrupole moment to the electron's electromagnetic field and the magnetic coupling of electrons with each other or nuclei with each other.
\end{enumerate}

\subsubsection{g-tensor and A-tensor}
  In the spin Hamiltonian above different interactions have been grouped with square brackets into three packages. The latter package $\left[\mathcal{H}_{NZ} + \mathcal{H}_{NCS} + \text{weaker interactions}\right]$ simply marks interactions which we are allowed to neglect in the case of high field EPR. When the external magnetic field $\vec{B}_0$ becomes sufficiently strong, their contribution diminishes in comparison with the interactions depending on $\vec{B}_0$.

  The former package $\left[\mathcal{H}_{EZ} + \mathcal{H}_{ECS} + \mathcal{H}_{LS}\right]$ marks major interactions linear in spin. In EPR the overall behaviour of those interactions is summarized in the \emph{g-tensor}:
  \begin{equation}
    \mathcal{H}_\text{linear} = \mu_B\ \mathbf{S} \cdot g \cdot \vec{B}_0
  \end{equation}

  The second package only including the hyperfine interaction characterizes the term bilinear in spin: the coupling between one spin and another. Though not evident from the sketch above, but those interactions are anisotropic in general and thus summarized by the A-tensor in the case of EPR:
  \begin{equation}
    \mathcal{H}_\text{bilinear} = \mathbf{S} \cdot A \cdot \mathbf{I}
  \end{equation}

  One might wonder, why the spin-orbit interaction does not contribute to the bilinear part. In \cite[chap 11.2, p. 505ff]{slichter} one finds a dedicated explanation why spin-orbit coupling results in a changed effective magnetic field and thus rather contributes to the $g$-tensor, very much like the chemical shift.
  %Slichter S.505 ff
  %Those interaction tensors are diagonizable matrices. Assume the $3 \times 3$ g-tensor has three eigenvalues $g_{xx}$, $g_{yy}$ and $g_{zz}$ on his diagonal. $g$ is called rhombic in the common case $g_{xx} \neq g_{yy} \neq g_{zz}$. In the special case $g_{xx} = g_{yy} = g_{zz}$ g is said to be \emph{isotropic}. In EPR practice, g and other tensors are usually quantified by their isotropic part and the anisotropic deviation from it:
%\begin{align}
% g_\text{iso} & = \frac{1}{3} Tr(g) = \frac{1}{3} (g_{xx} + g_{yy} + g_{zz})\\
% g_\text{aniso} & = g - g_\text{iso} \cdot I
%\end{align}
%where $I$ is the identity matrix.
  Another possible self-interaction $\mathcal{H}_\text{quadratic} = \mathbf{S} \cdot A \cdot \mathbf{S}$ we are not going to encounter in the case of high field EPR.

\subsection{Spin formalism}
Our aim is to understand the mechanisms employed in Spinach's simulation, and we are especially curious about the scaling of Spinach's memory and CPU time consumption. Hence we will examine the mathematical formalism directly underlying numerical computation more thoroughly.

\subsubsection{Quantum states and measurments done on them}
Any allowed spin state $| \psi \rangle$ can be written as a linear superposition of an orthogonal basis set of a Hilbert  space spanned by all allowed \emph{azimuthal quantum number} states $| m \rangle$:
\begin{equation}
 | \psi \rangle = \sum_m a_m | m \rangle 
\label{eq-orthonormal-basis}
\end{equation}
where the amplitudes are complex $a_m = |a_m| e^{i\phi_m}$ with phase $\phi_m$ and magnitude $|a_m|$. The $|m\rangle$ can be represented by a proper scaled basis of choice, but the $m$ lable offers a general independent representation.
 
All measurements to be done on a spin system yield eigenvalues of a linear operator associated with the particular measurement. The corresponding observed physical quantity is called \emph{observable}. Measuring the spin component of a system in one of the basis states along the z-axis $\mathbf{S_z}$ thus yields
\begin{equation}
  \mathbf{S_z} |m\rangle = m |m\rangle
\end{equation}
The orthogonal basis can be normalized by requiring the inner product of basis vectors to be
\begin{equation}
 \langle m|m'\rangle = \delta_{m m'}
  \label{eq-orthonormality}
\end{equation}

\begin{comment}
This requirement automatically defines the corresponding \emph{bras} for the \emph{ket} states. For a system of $S=\frac{1}{2}$ and thus $m=\pm \frac{1}{2}$ we have
\begin{align} 
 |\tfrac{1}{2}\rangle = \begin{bmatrix} 1 \\ 0 \end{bmatrix}, \quad |-\tfrac{1}{2}\rangle = \begin{bmatrix} 0 \\ 1 \end{bmatrix}\\
 \langle\tfrac{1}{2}| = \begin{bmatrix} 1 & 0 \end{bmatrix}, \quad \langle-\tfrac{1}{2}| = \begin{bmatrix} 0 & 1 \end{bmatrix} 
\end{align}
yielding the operator for the spin z-component observable 
\begin{equation}
 S_z = \begin{bmatrix} \tfrac{1}{2} & 0 \\ 0 & -\tfrac{1}{2} \end{bmatrix}
\end{equation}
\end{comment}

If a spin system exists in the eigenstate $|m\rangle$ of $\mathbf{S_z}$, then the measurement of $\mathbf{S_z}$ will yield
\begin{equation}
 \langle m | \mathbf{S_z} | m \rangle = m
\end{equation}
The measurement on a general superposition will yield
\begin{align}
 \langle \psi | \mathbf{S_z} | \psi \rangle & = \sum_{m,m'} a_m^* a_{m'} \langle m' | \mathbf{S_z} | m \rangle\\
  & = \sum_{m,m'} a_m^* a_{m'} m \langle m' | m \rangle\\
  & = \sum_{m} |a_{m}|^2  m
\end{align}
due to the orthormality of the basis set.

\subsubsection{Evolution operator and time propagation}
In the following we shall make use of matrix exponentials to express some quantum mechanical operators. The defintion of the exponential
\begin{equation}
 e^x = \sum_{k=0}^\infty \frac{x^k}{k!} = 1 + x + \frac{x^2}{2} + \frac{x^3}{6} + ...
\end{equation}
can be easily applied to square matrices, eg.:
\begin{equation}
 e^{i \phi A } = I + i \phi A - \frac{(\phi A)^2}{2!} - i \frac{(\phi A)^3}{3!} + \frac{(\phi A)^4}{4!} + i \frac{(\phi A)^5}{5!} - ...
\end{equation}
such that exponentials are defined for matrices as well.

\label{sec-dynamics}
In case of a stationary Hamiltonian, the Schr\"odinger equation 
\begin{equation}
  i \frac{\partial}{\partial t} | \psi(t) \rangle = \mathcal{H} |\psi(t) \rangle
\end{equation}
has the solution
\begin{equation}
  |\Psi(t)\rangle = U(t) | \psi(0) \rangle
  \label{eq-psi-general-solution}
\end{equation}
where 
\begin{equation}
 U(t) = e^{-i \mathcal{H} t}
  \label{eq-evolution}
\end{equation}
is called the \emph{evolution operator}.

In case of a time-dependent, but piecewise-constant Hamiltonian the solution has the form
\begin{equation}
 |\Psi(t)\rangle = \left[ \prod_k e^{-i\mathcal{H}_k \Delta t_k} \right] |\Psi(0)\rangle
  \label{eq-time-propagation}
\end{equation}
This is the basis of numerical time propagation.

\subsubsection{Density operator and spin ensembles}
%Slichter S. 157ff
Due to equation (\ref{eq-orthonormal-basis}) the expectation value of an observable $A$ can be expressed as 
\begin{equation}
 \langle A \rangle = \langle \psi | A | \psi \rangle = \sum_{m,n} c_m^* c_n \langle m | A | n \rangle
  \label{eq-observable-representation}
\end{equation}
Now, when the expectation value of a certain observable is required, we are always interested in the product $c_m^* c_n$ rather than the distinct $c_n$, thus we can think of a matrix representation of those probabilities and define an operator $P$ with
\begin{equation}
 \langle n | P | m \rangle = c_n c_m^*
\end{equation}
Equation (\ref{eq-observable-representation}) becomes
\begin{equation}
 \langle A \rangle = \sum_{m,n} \langle n | P | m \rangle \langle m | A | n \rangle
  \label{eq-P-A-representation}
\end{equation}
Since $|m\rangle$ form an orthonormal basis set, the results of $A$ and $P$ acting on a basis vector can be expanded in the basis:
% \langle l | P | m \rangle = a_l due to orthononormality
\begin{align} 
 P|m\rangle & = \sum_l a_l |l\rangle = \sum_l \langle l |P|m\rangle |l\rangle\\
 A|n\rangle & = \sum_m b_m |m\rangle = \sum_m \langle m |A|n\rangle |m\rangle 
\end{align}
since the $a_l$ and $b_a$ may be found as
\begin{align}
  \langle l |P|m\rangle & = \sum_{l'} a_{l'} \langle l'|l\rangle = a_l\\
  \langle m |A|n\rangle & = \sum_{m'} b_{m'} \langle m'|m\rangle = a_m\\
\end{align}
allowing the following expression to be rewritten
\begin{align}
 \Rightarrow P A |n\rangle & = \sum_m P|m\rangle \langle m | A | n \rangle \\
  & = \sum_{l,m} |l\rangle \langle l | P | m \rangle \langle m | A | n \rangle \\
  \Rightarrow \langle n | P A | n \rangle & = \sum_{l,m} \langle n|l\rangle \langle l | P | m \rangle \langle m | A | n \rangle \\
  & = \sum_{l,m} \delta_{ln} \langle l | P | m \rangle \langle m | A | n \rangle \\
  & = \sum_{m} \langle n | P | m \rangle \langle m | A | n \rangle
\end{align}
Comparing with equation (\ref{eq-P-A-representation}) we find
\begin{equation}
 \langle A \rangle = \sum_n \langle n | P A | n \rangle = Tr(P A) = Tr(A P)
 \label{eq-A-P-trace}
\end{equation}
where $Tr$ is the trace -- the total sum of the matrix' diagonal elements.
$P$ is an Hermitian operator since
\begin{equation}
 \langle n|P|m\rangle = c_n c_m^* = (c_m c_n^*)^* = \langle m |P|n\rangle^*
\end{equation}
and we might as well write
\begin{equation}
 \langle A \rangle = Tr(P^\dagger A) = Tr(A^\dagger P)
\label{eq-rho-observable}
\end{equation}

%Slichter S. 159, Callaghan S. 78
In EPR we pulse a powder sample. Theoretically this means a measurement on an ensemble of many spin systems with many (most generally different) spin states $|\psi\rangle$ instead of determining the state of a single system. The observable averaged about the whole statistical ensemble is written as
\begin{align}
 \overline{\langle A \rangle} & = \overline{\langle \psi | A | \psi \rangle} \\
  & = \sum_\psi p_\psi \langle \psi | A | \psi \rangle \\ 
  & = \sum_\psi p_\psi \left( \sum_{m,n} c_m^* c_n \langle m | A | n \rangle \right) \\
  & = \sum_{m,n} \left( \sum_\psi p_\psi c_m^* c_n \right) \langle m | A | n \rangle \\
  & = \sum_{m,n} \overline{c_m^* c_n} \langle m | A | n \rangle
  \label{eq-ensemble-representation}
\end{align}
where $p_\psi$ is an appropriate statistical averaging weight chosen according to the occupancy of $|\psi\rangle$. On this basis we introduce the \emph{density matrix operator}
\begin{equation} 
 \langle n | \rho | m \rangle = \overline{c_m^* c_n} = \overline{\langle n | P | m \rangle}
\end{equation}
whereby equation (\ref{eq-ensemble-representation}) can be expressed in analogy to equation (\ref{eq-A-P-trace}) as
\begin{equation}
 \overline{\langle A \rangle} = \sum_{n,m} \langle n | \rho | m \rangle \langle m | A | n \rangle = \sum_{n} \langle n | \rho A | n \rangle = Tr(\rho^\dagger A) = Tr(A^\dagger \rho)
\end{equation}
Another beautiful expression for the density matrix can be derived by noticing that
\begin{align}
 \langle n |\psi \rangle \langle \psi | m \rangle & = \langle n | \left( \sum_{n'} c_{n'} |n' \rangle \right) \left( \sum_{m'} c_{m'}^* \langle m' | \right) | m \rangle \\ & = \sum_{n',m'} c_{n'} c_{m'}^* \langle n | n' \rangle \langle m' | m \rangle = c_n^* c_m  = \langle n | P | m \rangle \\
  \Rightarrow |\psi\rangle\langle\psi| & = P \quad; \quad \overline{|\psi\rangle\langle\psi|}  = \rho
\label{eq-density-matrix}
\end{align}

\subsubsection{Liouville equation}
% Kuprov L9
Under comparison with the general Schr\"odinger equation and its complex conjugate below
\begin{align}
 \langle \psi | \frac{\partial}{\partial t} |\psi\rangle  & = -i \langle \psi | \mathcal{H} |\psi\rangle \\
  \left( \frac{\partial}{\partial t} \langle \psi | \right)  |\psi\rangle
   & = \sum_{m,n} \frac{\partial c_m^*}{\partial t} c_n \langle m | n \rangle 
   =  \sum_{m} \frac{\partial c_m^*}{\partial t} c_m \\
   & = \left( \sum_{m} c_m^* \frac{\partial c_m}{\partial t}\right)^*
   = \left( \langle \psi | \frac{\partial}{\partial t} |\psi\rangle \right)^* = i \langle \psi |\mathcal{H} |\psi\rangle
\end{align}
the density matrix' equation of motion can be derived by differentiating equation (\ref{eq-density-matrix}) with respect to time:
\begin{align}
 \frac{\partial}{\partial t} \rho & = \left( \frac{\partial}{\partial t} | \psi \rangle \right) \langle \psi | + | \psi \rangle \left( \frac{\partial}{\partial t} \langle \psi | \right)  \\
  & = - i \mathcal{H} |\psi\rangle\langle\psi| + i |\psi\rangle\langle\psi| \mathcal{H}  \\
  & = -i ( \mathcal{H} \rho - \rho \mathcal{H} ) = -i [ \mathcal{H}, \rho ] 
  \label{eq-liouville}
\end{align}
We arrived at the \emph{Liouville equation}. Its general solution follows directly from the Schr\"odinger equation's solution (\ref{eq-psi-general-solution}):

\begin{equation}
 \rho(t) = |\psi(t)\rangle \langle \psi(t)| = e^{-i \mathcal{H} t} | \psi(0) \rangle \langle \psi(0) | e^{i \mathcal{H} t} = e^{-i \mathcal{H} t} \rho(0) e^{i \mathcal{H} t}
\end{equation}

\subsubsection{Superoperators, Liouville space}
The Hamiltonian $\mathcal{H}$ is an operation defined on the space of vectors, similarly the commutation operator $\mathcal{L} = [\mathcal{H}, \cdot ]$ is an operation defined on the space of operators. Thus it is called the \emph{Liouvillian superoperator}. The spaces one usually comes to deal with when treating spin dynamics are

\begin{itemize}
 \item the space where all states live. States are represented as a vector (\ref{eq-orthonormal-basis}) of dimension $N$, and with the scalar product $\langle \phi | \psi \rangle$ they fulfill every requirement to span an $N$-dimensional \emph{Hilbert space}. This space is isomorph to $\mathbb{C}^N$.
  \item the space where all operators which act on spin states live. Operators such as $\mathcal{H}$ are represented by $N\times N$-matrices, thus the space spanned by those operators is $N^2$-dimensional and isomorph to $\mathbb{C}^{N^2}$. There exist many possible scalar products, so again we deal with a Hilbert space. The special operator space, where we choose $Tr(A^\dagger B)$ as the scalar product is known as the \emph{Liouville space} in spin dynamics.
  \item the space where all \emph{superoperators} which act on operators live. Superoperators such as $\mathcal{L} = [\mathcal{H}, \cdot ]$ are represented by $N^2 \times N^2$ matrices, thus the space spanned by those superoperators is $N^4$-dimensional and isomorph to $\mathbb{C}^{N^4}$. Again, we chose the scalar product $Tr(A^\dagger B)$ for this Hilbert space and call it \emph{superoperator space}.
\end{itemize}

Now, if we represent states as vectors and operators as matrices, how come we do not have to represent superoperators as more complex objects like ``three-dimensional matrices''? The mathematical trick is to stretch the original operator matrix $\rho$ column-wise into a vertical vector:
\begin{equation}
 \rho = \begin{pmatrix} \vec{\rho}_1,\vec{\rho}_2,\ldots,\vec{\rho}_N \end{pmatrix} \rightarrow
  |\rho \rangle = \begin{pmatrix} \vec{\rho}_1 \\ \vec{\rho}_2 \\ \ldots \\ \vec{\rho}_N \end{pmatrix} 
\end{equation}
Of course, every single column vector of $\rho$ has dimension $N$, so $|\rho\rangle$ has dimension $N^2$. The trace of two matrices $A$, $B$ stretches into a vector scalar product:
\begin{equation}
 Tr( A^\dagger B ) = \sum_{n,k} A_{nk}^* B_{nk} = \sum_{n'} A_{n'}^* B_{n'} = \langle A | B \rangle
\end{equation}
This allows the calculation of a matrix scalar product in $O(N^2)$ runtime.

With the operator stretched into a vector, the superoperator can accordingly be stretched into an $N^2 \times N^2$ matrix representation. The matrix version of the Liouvillian is the sum of two Kronecker products
\begin{equation}
 \mathcal{L} = E \otimes \mathcal{H}^T - \mathcal{H} \otimes E
\end{equation}
%insert proof
where $E$ is the $N \times N$ unity matrix. 

%Callaghan S. 85
For visualization, a spin-$\tfrac{1}{2}$ system with the two-dimensional Hilbert space basis consisting of $|-\tfrac{1}{2}\rangle$ and $|\tfrac{1}{2}\rangle$ yields a four-dimensional Liouville space, and as its orthonormal basis we might choose $\tfrac{1}{2}E, J_x, J_y$ and $J_z$, or $E, I_z, -\tfrac{1}{\sqrt{2}} J_+$ and $\tfrac{1}{\sqrt{2}} J_-$, which are all $2\times 2$ matrices. Similarly a spin-$1$ system with the three-dimensional Hilbert space spanned by $|-1\rangle, |0\rangle$ and $|1\rangle$ requires a nine-dimensional Liouville basis, and in general a spin system of $N$ possible states yields an $N^2$ dimensional Liouville space (and an $N^4$ dimensional superoperator space). 
%To illustrate the explosion of dimensions, a spin system of $10$ spin-$\tfrac{1}{2}$ particles allows $N=2^{10} = 1024$ states, requring an $N^2 = 1,048,576$ dimensional Liouville basis. Thus in numerical computation this basis is reduced under loss of information to yield acceptable memory costs. 
The next section treats the question, how to choose an apropriate basis out of many orthonormal possibilities.

\subsubsection{Choice of basis set and irreducible spherical tensors}
When we are looking for a suitable basis of the Liouville space to conduct some spin dynamics simulation, the perfect choice would be \emph{eigenoperators} $S_k$ of the Liouvillian, since they are invariant under all interactions of the system:
\begin{equation}
  \mathcal{L} S_k = l_k S_k
\end{equation}
To find those eigenoperators in their vector form, one could diagonalize the Liouvillians matrix representation. Unfortunately the computation costs would be enourmous due to the $N^4$ dimensions of the superoperator space. A wise choice would be a set of eigenoperators invariant under commutation with $J_z$, since this operator characterizes the dominating Zeeman interaction in EPR. Or even better, a set of operators invariant under rotations, since we have to examine the spin system from many different angles to average the powder spectrum.

%Callaghan S. 89
%Slichter S. 490
As we know, the angular momentum operators $J_x$, $J_y$ and $J_z$ generate rotations. It is possible to define a family of operators $T_{lm}$ called \emph{irreducible spherical tensors (IST)} of rank $l$ and order $m$, which fulfill the commutation relations
\begin{align}
 [J_\pm,T_{lm}] & = \sqrt{l(l+1)-m(m\pm1)} T_{l(m\pm1)} \\
  [J_z, T_{lm}] & = m T_{lm}
  \label{eq-tlm-commutators}
\end{align}
In the space of operators they are the analogon to the spherical harmonics in the space of wavefunctions, for every $l$ there exist $2l+1$ independent IST with $m = -l, -l+1, \dots , l-1, l$ and any rotation transforms $T_{lm}$ into a linear combination of $T_{lm'}$ with same rank $l$:
%Starting from the commutation relations (\ref{eq-tlm-commutators}), it can be shown that a rotation of $T_{lm}$ results in 
\begin{equation}
 R(\alpha,\beta,\gamma) \ T_{lm} = \sum_{m'=-l}^l \mathfrak{D}_{m',m}^{(l)}(\alpha,\beta,\gamma) \ T_{lm'}
  \label{eq-wigner-rotation}
\end{equation}
The matrix elements $\mathfrak{D}_{m,m'}^{(l)}(\alpha.\beta,\gamma)$ are called \emph{Wigner functions} and make up the \emph{Wigner rotation matrix} of rank $l$ corresponding to a certain rotation $R(\alpha,\beta,\gamma)$. They can be evaluated with the spherical harmonics
\begin{equation}
 \mathfrak{D}_{m,m'}^{(l)}(\alpha.\beta,\gamma) = \langle Y_{lm}|R(\alpha,\beta,\gamma)|Y_{lm'} \rangle
\end{equation}
Just as the spherical harmonics $Y_{lm}$ form an orthonormal basis on the unit sphere of the wave functions' Hilbert space, do all IST $T_{lm}$ form an orthonormal basis on the Liouville space of operators, and thus any operator, e.g. the density matrix $\rho$ of dimension $N^2$, may be expanded in a linear combination of IST:
\begin{equation}
 \rho = \sum_{l=0}^{N-1} \sum_{m=-l}^l a_{lm} T_{lm}
\end{equation}
Obviously, a spin-$\tfrac{1}{2}$ density matrix of dimension $N^2=4$ can be fully represented by the single zero-order IST and the three first-order IST, while for a $N^2=9$ Liouville space all IST of second rank are required as well. 
%The first few IST of one single spin happen to be

The lowest rank IST is the identity operator, the first rank IST are linear superpositions of $J_x, J_y$ and $J_z$. All higher rank IST $T_{LM} (J_1,J_2)$ can be formed as products of lower rank IST following the rule for combining angular momenta:
\begin{equation}
 T_{LM}(J_1,J_2) = \sum_{m_1,m_2} \langle l_1 m_1 l_2 m_2 | L M \rangle \ T_{l_1 m_1} (J_1) \ T_{l_2 m_2} (J_2)
\end{equation}
where the \emph{Clebsch-Gordan coefficients} $\langle l_1 m_1 l_2 m_2 | L M \rangle$ are zero except for $m_1 + m_2 = M$. $K$ ranges from $|k_1-k_2|$ to $k_1+k_2$. The new IST again obey the rotational features above. Taking $k_1 = k_2 = 1$ we can produce the nine tensors below for $J_1 = J_2 = J$  
\begin{equation}
 \begin{matrix*}[l]
	&	& \quad \quad & &		& \quad \quad     & T_{2 -2}	& = \tfrac{1}{2} J_-^2 \\[1em]
	&	& & T_{1 -1}	& = \tfrac{1}{\sqrt{2}} J_-	& & T_{2 -1}	& = \tfrac{1}{2} ( J_z J_- + J_- J_z) \\[1em]
  T_{0 0}	& = E 	& & T_{1 0}	& = J_z 			& & T_{2 0} 	& = \tfrac{1}{\sqrt{6}} (3J_z^2-2E) \\[1em]
	&	& & T_{1 1}	& = -\tfrac{1}{\sqrt{2}} J_+	& & T_{2 1}	& = - \tfrac{1}{2} ( J_zJ_+ + J_+ J_z)\\[1em]
	&	& &		&				& & T_{2 2}	& = \tfrac{1}{2} J_+^2
 \end{matrix*}
\end{equation}
while for $J_1 \neq J_2$ we can produce 16 independent tensors, of which the second rank tensors read
\begin{equation}
 \begin{matrix*}[l]
	 T_{2 -2}	& = J_{1-} J_{2-} \\[1em]
	 T_{2 -1}	& = ( J_{1z} J_{2-} + J_{1-} J_{2z}) \\[1em]
	 T_{2 0} 	& = \sqrt{\tfrac{2}{3}} (3 J_{1z} J_{2z}-J_1\cdot J_2) \\[1em]
	 T_{2 1}	& =  - ( J_{1z} J_{2+} + J_{1+} J_{2z}) \\[1em]
	 T_{2 2}	& = - J_{1+} J_{2+}
 \end{matrix*}
\end{equation}
From there on it would be possible to construct IST for an arbitrary number of spins, but looking at the most general interaction included in an EPR Hamiltonian, the maximum number of interacting spins amounts to two, e.g. $\vec{L}$ and $\vec{S}$ coupled by the interaction tensor $A$ 
\begin{equation}
 \vec{L} \cdot A \cdot \vec{S} = \sum_{k,n} a_{kn} L_k S_n \quad \text{with} \quad  k,n = x,y,z
\end{equation}
of which linear and quadratic interactions form special cases. Having a linear superposition of $L_k S_n$ terms, the interaction must be expandeble in a basis consisting of rank two IST at maximum. Practically, first rank terms' contribution diminishes and hence is ignored:
\begin{equation}
 \vec{L} \cdot A \cdot \vec{S} = \sum_{l=0}^2 \sum_{m=-l}^l \alpha_{lm} T_{lm} (L,S) \approx \alpha_{00} T_{00} + \sum_{m=-2}^2 \alpha_{2m} T_{2m}(L,S)
\end{equation}
Therefore the whole anisotropic Hamiltonian consisting of scalar-spin and spin-spin interactions of $N$ spins may be expanded in second rank IST representation (ignoring quadratic self-interaction):
\begin{equation}
 \mathcal{H} = \mathcal{H}_{\text{iso}} + \sum_L \sum_{m=-2}^2 \alpha_{L,m}\ T_{2m} (L) + \sum_{L,S\neq L} \sum_{m=-2}^{2} \beta_{L,S,m}\ T_{2m}(L,S)
\end{equation}
The special feature of this expansion is its behaviour under rotations $R(\alpha,\beta,\gamma)$ -- the Hamiltonian inherits the IST's rotational transformation rule (\ref{eq-wigner-rotation}):
\begin{align}
 R \mathcal{H} & = \mathcal{H}_\text{iso} +  \sum_L \sum_{m=-2}^2 \alpha_{L,m}\ R T_{2m} (L) + \sum_{L,S\neq L} \sum_{m=-2}^{2} \beta_{L,S,m}\ R T_{2m}(L,S) \\
  & = \mathcal{H}_\text{iso} +  \sum_L \sum_{m=-2}^2 \alpha_{L,m} \sum_{m'=-2}^{m'} \mathfrak{D}_{mm'}^{(2)} T_{2m'} (L) + \sum_{L,S\neq L} \sum_{m=-2}^{2} \beta_{L,S,m} \sum_{m'=-2}^{2} \mathfrak{D}_{mm'}^{(2)} T_{2m'}(L,S) \\
  & = \mathcal{H}_\text{iso} +  \sum_{m=-2}^2 \sum_{m'=-2}^{2} \mathfrak{D}_{mm'}^{(2)}  \left( \sum_L  \alpha_{L,m} T_{2m'} (L) + \sum_{L,S\neq L} \beta_{L,S,m} T_{2m'}(L,S) \right)\\
  & =  \mathcal{H}_\text{iso} +  \sum_{m,m'=-2}^{2} \mathfrak{D}_{mm'}^{(2)} Q_{mm'} \quad \text{with} \quad 
  Q_{mm'} = \sum_L  \alpha_{L,m} T_{2m'} (L) + \sum_{L,S\neq L} \beta_{L,S,m} T_{2m'}(L,S)
\end{align}
The 25 elements $Q_{mm'}$ of the $5\times 5$ matrix $Q$ are called \emph{rotational basis operators}. They store the anisotropic part of any spin system's Hamiltonian in such a way that any rotational orientation of the system yields a linear combination of this rotational basis with precomputable Wigner function coefficients. Notice that each $Q_{mm'}$ has dimensions $N \times N$.  

\subsection{Understanding the experiment}

\subsubsection{Rotating reference frame}
% Callaghan p.110 4.2.1
% Slichter p. 27
A magnetic field $B_0$ applied along the z-axis causes a magnetic moment to precess around the z-axis at the Larmor frequency $\omega_0$. With this classical approach as a starting point it is possible to explain a fair amount of EPR phenomena, but since we want to get used to spin formalism, we will explain a spin system's behaviour from the quantum mechanical perspective right from the beginning. Since the electron's magnetic moment is proportional to its angular momentum $\vec{\mu} = \gamma \mathbf{J}$ with the \emph{Land\'e g-factor} $\gamma$, the interaction energy $E = - \vec{\mu} \cdot \vec{B}$ and thus the Hamiltonian, the evolution operator and the Schr\"odinger equation's solution can be expressed as
\begin{equation}
  \mathcal{H} = - \gamma B_0 \mathbf{J_z}, \quad U(t) = e^{i \gamma B_0 t \mathbf{J_z}}, \quad |\psi(t)\rangle = e^{i \gamma B_0 t \mathbf{J_z}} |\psi(0)\rangle = e^{i \omega_0 t \mathbf{J_z}} |\psi(0)\rangle \quad \text{with} \quad \omega_0 = \gamma B_0
\end{equation}
Analogous to the classical approach, the time dependent solution must be a rotation of the initial state by angle $\phi = -\omega_0 t$, and we can identify 
\begin{equation}
 \mathbf{R_z}(\phi) = e^{-i\phi \mathbf{J_z}}
\label{eq-z-rotation}
\end{equation}
as an rotation operator around the z-axis. $\phi > 0$ results in an \emph{active} rotation of the state in ``positive'', anticlockwise direction, whereas $\phi < 0$ results in  a rotation in ``negative'', clockwise direction. Likewise we can speak of $\phi > 0$ causing a \emph{passive} rotation of the reference frame in negative, clockwise direction, whereas $\phi < 0$ rotates the reference frame in positive, anticlockwise direction.

If we want to determine an observable $\mathbf{A}$ of the rotated state $|\psi(t)\rangle$, we find
\begin{align}
  \langle \psi(\phi) | \mathbf{A} | \psi(\phi) \rangle & = \langle \psi(0) | e^{-i \phi \mathbf{J_z}}\ \mathbf{A}\ e^{i \phi \mathbf{J_z}} | \psi(0) \rangle \\
  & = \langle \psi(0) | \mathbf{A'}(\phi) | \psi(0) \rangle \quad \text{with} \quad \mathbf{A'}(\phi) = e^{-i \phi \mathbf{J_z}}\ \mathbf{A}\ e^{i \phi \mathbf{J_z}}
\end{align}
it being the same as applying an rotated operator $\mathbf{A'}$ on the unrotated state $|\psi(0)\rangle$. Say $|\psi(\phi)$ is rotated in positive sense, then the operator $\mathbf{A'}$ must be rotated in the negative sense. The two perspectives must correspond to two different reference frames. In the first case we observe a rotated system from the unrotated lab frame, whereas in the second case the axis of our reference frame are aligned with the spin system, such that it appears unrotated in our frame. Hence we can convert back and forth between resting frame and rotating frame:

\begin{align}
 |\psi \rangle & = e^{-i \omega_1 t \mathbf{J_z}} | \psi' \rangle \\
  |\psi' \rangle & = e^{i \omega_1 t \mathbf{J_z}} | \psi \rangle 
\end{align}

And if we know the Hamiltonian $\mathcal{H}$ for $|\psi\rangle$ in one frame, we can find the rotating Hamiltonian $\mathcal{H}'$ in the frame of $|\psi'\rangle$ by plugging into the Schr\"odinger's equation:
\begin{align} 
  \frac{\partial}{\partial t} |\psi\rangle  =  \frac{\partial}{\partial t} \left( e^{-i \omega_1 t \mathbf{J_z}} | \psi' \rangle  \right) & = - i \omega_1 t \mathbf{J_z} \ e^{-i \omega_1 t \mathbf{J_z}} | \psi' \rangle + e^{-i \omega_1 t \mathbf{J_z}} \frac{\partial}{\partial t} | \psi' \rangle \\
  i\frac{\partial}{\partial t} |\psi\rangle   & = \mathcal{H} |\psi\rangle  \\
  \Rightarrow i \left( - i \omega_1 \mathbf{J_z} \ e^{-i \omega_1 t \mathbf{J_z}} | \psi' \rangle + e^{-i \omega_1 t \mathbf{J_z}} \frac{\partial}{\partial t} | \psi' \rangle \right)& = \mathcal{H} \left( e^{-i \omega_1 t \mathbf{J_z}} |\psi'\rangle \right) 
  \quad \left. \right| \cdot e^{i \omega_1 t \mathbf{J_z}},\ e^{i \omega_1 t \mathbf{J_z}} \mathbf{J_z} e^{-i \omega_1 t \mathbf{J_z}}= \mathbf{J_z} \\
  \Leftrightarrow \omega_1 \mathbf{J_z} | \psi' \rangle + i \frac{\partial}{\partial t} | \psi' \rangle & = \left( e^{i \omega_1 t \mathbf{J_z}} \mathcal{H} e^{-i \omega_1 t \mathbf{J_z}} \right) |\psi'\rangle \\
  \Leftrightarrow i \frac{\partial}{\partial t} | \psi' \rangle & = \left( e^{i \omega_1 t \mathbf{J_z}} \mathcal{H} e^{-i \omega_1 t \mathbf{J_z}}- \omega_1  \mathbf{J_z} \right) |\psi'\rangle \\
  & = \mathcal{H}'|\psi'\rangle \\
 &\text{with} \quad \mathcal{H}' = e^{i \omega_1 t \mathbf{J_z}} \mathcal{H} e^{-i \omega_1 t \mathbf{J_z}}- \omega_1  \mathbf{J_z} 
  \label{eq-rotating-hamiltonian}
\end{align}


\begin{comment}
Suppose we are changing from the lab frame to a frame which is rotating anticlockwise with angular velocity $\omega_1$ around the z-Axis. 
The passive clockwise rotation by $\omega_1 t$ converting from rotating frame to inertial frame is realized by the operator $R_z(\omega_1 t) = e^{-i \omega_1 t I_z}$, while an passive anticklockwise transition from lab frame to rotating frame is realized by the operator $R_z(-\omega_1 t) =  e^{i \omega_1 t I_z}$. Thus we can apply any operator $A$ we know in the inertial frame, packed in a sandwich of rotational operators $R(-\omega_1 t) A R(\omega_1 t)$, to receive the value of an observable in the rotating frame. Let's convert the Hamiltonian to our rotating frame:
\begin{equation}
 \mathcal{H}_\text{rot} = e^{i \omega_1 t I_z} \mathcal{H} e^{-i \omega_1 t I_z}
\end{equation}
We transform the Schr\"odinger equation for wave $|\Phi(t)\rangle$ to the rotating frame with the rotated wave function $|\Phi'(t)\rangle$:
\begin{align} 
  i\frac{\partial}{\partial t} |\Phi'(t)\rangle   & = \mathcal{H} |\Phi'(t)\rangle  \\
  \Rightarrow i \frac{\partial}{\partial t} \left(e^{-i \omega_1 t I_z} |\Phi'(t)\rangle \right) & = \left( e^{-i \omega_1 t I_z} \mathcal{H}_\text{rot} e^{i \omega_1 t I_z} \right) \left( e^{-i \omega_1 t I_z} |\Phi'(t)\rangle \right)
  %\Leftrightarrow 
\end{align}
%GRAPHICS%
Differentiating the equation's left hand side and rearranging yields
\begin{align}
 i\frac{\partial}{\partial t} |\Phi'(t)\rangle & = (\mathcal{H}_\text{rot} - \omega_1 I_z) |\Phi'(t)\rangle \\
  & = \mathcal{H}' |\Phi'(t)\rangle \quad \text{with} \quad \mathcal{H}' = e^{i \omega_1 t I_z} \mathcal{H} e^{-i \omega_1 t I_z} - \omega_1 _z
  \label{eq-rotating-hamiltonian}
\end{align}
\end{comment}

\subsubsection{Resonant frequency field}
Suppose we observe the equilibrium system due to Zeeman interaction $\mathcal{H} = - \gamma B_0 J_z$ from a frame rotating with $\omega_1$. According to equation (\ref{eq-rotating-hamiltonian})
\begin{equation}
  \mathcal{H'} = e^{i \omega_1 t \mathbf{J_z}} \mathcal{H} e^{-i \omega_1 t \mathbf{J_z}}- \omega_1 \mathbf{J_z} = -\gamma(B_0 + \frac{\omega_1}{\gamma}) \mathbf{J_z}
\end{equation}
The rotating frame introduces another term acting like an additional magnetic field. By choosing the angular velocity to equal the Zeeman effect's Larmor frequency $\omega_1 = -\gamma B_0$ we can make the net magnetic field vanish in the rotating frame. This is easy to imagine: The rotating frame just follows the system's Larmor precession, letting the system appear stationary.

Now it is easy to imagine what happens in the rotating frame, if we pulse the system by a transversal circularly polarized magnetic field $\vec{B}_1 = B_1 (\hat{x} \cos \omega_2 t + \hat{y} \sin \omega_2 t)$ and choose the frequency of $B_1$ to approximately equal the system's Larmor frequency around the static field $\omega_2 \approx \omega_1 = - \gamma B_0$. In this case of ``resonance'' the static magnetic field in the rotating frame disappears and the circularly polarized fiel appears to be static in x-direction. The static Hamiltonian\footnote{ for a prove of $e^{-i \omega_2 t \mathbf{J_z}} \mathbf{J_x} e^{i \omega_2 t \mathbf{J_z}} = \cos \omega_2 t \ \mathbf{J_x} + \sin \omega_2 t \ \mathbf{J_y}$ see \cite[chap 2.6 Exponential Operators, p. 27f]{slichter}}
\begin{align}
 \mathcal{H} = -\gamma \vec{B}_\text{tot} \cdot \mathbf{J}  & = - \gamma \left( B_0 \mathbf{J_z} + B_1 ( \cos \omega_2 t \ \mathbf{J_x} + \sin \omega_2 t \ \mathbf{J_y} ) \right) \\
  & = - \gamma \left( B_0 \mathbf{J_z} + B_1 e^{-i \omega_2 t \mathbf{J_z}} \mathbf{J_x} e^{i \omega_2 t \mathbf{J_z}} \right)
\end{align}
transforms to the rotating Hamiltonian
\begin{align}
\mathcal{H'} & = e^{i \omega_1 t \mathbf{J_z}} \mathcal{H} e^{-i \omega_1 t \mathbf{J_z}} \\
& = -\gamma \left( (B_0 + \frac{\omega_1}{\gamma}) \mathbf{J_z} + B_1 \mathbf{J_x} \right)  \quad \text{with} \quad \omega_2 = \omega_1\\
  & = - \gamma B_1 \mathbf{J_x} \quad \text{with} \quad \omega_1 = - \gamma B_0 
\end{align}
In case of using a linearly polarized instead of a circularly polarized pulse, it may be argued that the rotating Hamiltonian still looks the same, since a linearly polarized field may be decomposed into two circularly polarized components, rotating in opposite directions. In the rotating frame , one of those components just behaves like the $B_1$ field above, the other one oscillates so rapidly at $2\omega_2$, that the spins experience only the fluctuating field's average value of zero\footnote{this is argued in \cite[chap. 4.2.2 The resonant frequency field, p.111f]{nmr-ox}}. From the classical point of view, in the rotating frame the spins now precess around $B_1 \hat{x}'$ as they do around $B_0 \hat{z}$ in the resting frame. From the quantum mechanical point of view, spins are now inclined to undergoe quantized transitions from states aligned around $B_0$ into states aligned around $B_1$.

If the pulse is applied for a duration $\Delta t$ such that $\omega_1 \Delta t = \tfrac{\pi}{2}$, the spin system aligned along the z-axis will be reorientated along the y'-axis of the rotating frame. After the pulse, the system will evolve in time and relax into its equilibrium under the spin Hamiltonian's interactions. 

\begin{comment}
Now switching on the pulse $B_1$ in x-direction modifies the lab frame Hamiltonian\footnote{see \cite[Chap. 4.2.2 The resonant radiofrequency field, p.111f]{ox-nmr}}
\begin{equation}
 \mathcal{H} = - \gamma B_0 I_z - 2 \gamma B_1 \cos(\omega_1 t) I_x
\end{equation}
and the rotating frame Hamiltonian
\begin{equation}
  \mathcal{H}' = - \gamma ( B_0 + \frac{\omega_1}{\gamma}I_z) - \gamma B_1 I_x
\end{equation}
At resonant frequency the field in z-direction vanishes and the field component in x-direction causes a simple precession of the system's spin around the magnetic field axis at frequency $\omega_2 = - \gamma B_1$ in the rotating frame. Choosing an appropriate duration of the pulse $\omega_2 t_p = \tfrac{\pi}{2}$, the equilibrium magnetisation of the sample will be disturbed, since the system's spins are all tilted by $90^\circ$ around the x-axis into the x-y-plane. 
\end{comment}
\subsubsection{FID detection}
% Callaghan p. 123ff
%Insert graphics Callaghan p.124
When the spins are precessing around $B_1$ in the rotating frame, and undergoing a more complex motion resulting from a superposition of precession around the static $B_0$ and the rotating $B_1$, what physical quantity are we going to measure? As has been noticed, the system's magnetic moment is proportional to its spin orientation $\vec{\mu} \propto \mathbf{S}$, hence we want to record the system's total magnetization. For this purpose a detection coil is installed orthogonal to the static magnetic field $B_0$, which records the change of the spin system's oscillating magnetization via Faraday induction.
%\begin{equation}
% \vec{\nabla} \times \vec{E} = - \frac{\partial \vec{B}}{\partial t}
%\end{equation}

For $\tfrac{\pi}{2}$-pulse EPR, right after the pulse the spins lie in the x-y-plane of the lab frame, rotating around the z-axis, and together with them the magnetization $\vec{M}$. Say, the detection coil is aligned along the x-axis, then it will record the change of magnetization in x-direction $M_x$, and the coil's signal will oscillate with the spin system's Larmor frequency
\begin{equation}
 S(t) = S_0 \cos \omega_1 t = S_0  \frac{e^{-i \omega_1 t} + e^{i \omega_1 t}}{2}
\end{equation}
 %As well we might have a second coil aligned along the y-axis, and thereby a second channel to record the change of magnetization in y-direction. Then we can mix a complex signal
The signal is modulated with a complex oscillating signal $e^{i\omega t}$
\begin{equation}
 S'(t) = S(t) e^{i\omega t} = \frac{1}{2} S_0 \left( e^{-i (\omega_1-\omega) t} + e^{i (\omega_1+\omega) t} \right)
\end{equation}
and the sum frequency term is filtered out to yield
\begin{equation}
 S'(t) =\frac{1}{2} S_0 e^{-i (\omega_1-\omega) t}
\end{equation}


Neglecting any relaxation, the evolution of a density matrix titled into the x-y-plane by a $\tfrac{\pi}{2}$-pulse may be written as 
\begin{equation}
 \rho \propto \mathbf{J_y} \cos \omega_1 t + \mathbf{J_x} \sin \omega_1 t
\end{equation}
and if we express the density matrix in a rotating frame of velocity $\omega$
\begin{equation}
 \rho \propto \mathbf{J_y} \cos (\omega_1-\omega) t + \mathbf{J_x} \sin (\omega_1-\omega) t
\end{equation}
If we are able to evaluate $\mathbf{J_+} = \mathbf{J_x} + i \mathbf{J_y}$ as a ``complex observable'' in the rotating frame, it would yield\footnote{where the last line just reflects the relation between spin and magnetization in a sample of $N$ spin systems, see \cite[chap. 4.3.1 Free precession and Faraday detection, p. 125]{nmr-ox}}
\begin{align}
 Tr( \mathbf{J_+} \rho' ) & \propto i\ Tr(\mathbf{J_y}^2) \cos (\omega_1-\omega) t + Tr(\mathbf{J_x}^2) \sin (\omega_1-\omega) t \\
& \propto i ( \cos (\omega_1-\omega) t - i \sin (\omega_1-\omega) t ) \quad \text{since} \quad Tr(\mathbf{J_y}^2) = Tr(\mathbf{J_x}^2) \\
N\gamma \ Tr( \mathbf{J_+} \rho' ) & = i M_0 e^{-i (\omega_1-\omega) t} \propto \frac{1}{2} S_0 e^{-i (\omega_1-\omega) t} = S'(t)
\end{align}
Hence we see that the detection coil's modulated signal is just proportional to the magnetization we would observe in a reference frame rotating with the modulation frequency $\omega$, and same applies for a relaxing manetization $M(t)$ instead of $M_0$ modulating the signal. The $S'$ signal oscillates at frequency $\Delta \omega = \omega_1 - \omega$, and the conclusion to draw is that the rotating frame does not only constitute a handy tool to visualize the effect of a magnetic pulse, but proves equally useful in the detection process as well. Thus any simulation might well be performed without ever leaving the rotating frame, yielding the FID in form of the complex observable $\mathbf{J_+} = \mathbf{J_x} + i \mathbf{J_y}$.

\subsubsection{Real and imaginary spectrum}
insert
\subsubsection{Averaging over Lebedev grids}
Since we consider powder samples, we have to average the spectra of many differently orientated spin ensembles. Assuming each spin ensemble to be randomly orientated, we need a method to discretize the unit sphere in a way such that the resulting discrete orientations represent the infinite amount of continuous possible orientations most accurately and then perform numerical integration about the unit sphere. \emph{Gaussian spherical quadrature} is a powerful integration technique, and the most efficient sampling scheme for the sphere was developed by the Russian mathematician Lebedev. Lebedev grids provide a method of weighted discretization, depending on the resolution they are labeled with their rank $J$, and Spinach includes precomputed angles and weights for Lebedev grids up to rank 131. In table (\ref{tab-lebedev}) one finds the number of orientations for Lebedev grids of certain rank. 

\begin{figure}
  \begin{center}
 \begin{tabular}{|r|r|}
  \hline
  rank $J$	& orientations $N$ \\
  \hline
  47		& 770 \\
  53		& 974 \\
  59		& 1202 \\
  65		& 1454 \\
  77		& 2030 \\
  95		& 3074 \\
  101		& 3470 \\
  107		& 3890 \\
  113		& 4334 \\
  119		& 4802 \\
  125		& 5294 \\
  131		& 5810 \\
  \hline
 \end{tabular}
\caption{the number of orientation for selected Lebedev grids of rank $J$}
\label{tab-lebedev}
  \end{center}
\end{figure}
With the precomputed weights $w_i$ and orientations $\theta_i, \phi_i$, the evaluation of the integral $I$ of function $f$ on the unit sphere reduces to a sum
\begin{equation}
 I[f] = \sum_{i=1}^N w_i f(\theta_i,\phi_i)
\end{equation}


\begin{comment}
\subsection{Fourier transorm}
What happens during EPR from a quite general point of view? We excite a certain system with an electromagnetic signal and measure the system's response. In other words, the system $\Phi$ uses the time-resolved input $x(t)$ to generate output $y(t)$:
\begin{equation}
	y(x) = \Phi\{x(t)\}
\end{equation}
If we assume the system to be linear
\begin{equation}
 	\Phi\{\alpha x_1(t) + \beta x_2(t)\} = \alpha y_1(t) + \beta y_2(t)
\end{equation}
and time-invariant
\begin{equation}
	\Phi\{x(t-t_0)\} = y(t-t_0)
\end{equation}
we can expand the input function in a series of some orthonormal basis set $g_k(t)$, or in some integral transform in the continuous limit with basis $g(\tau,t)$ and define the system completely by its set of responses to the basis functions:
\begin{align}
	x(t) & = \sum_k \chi_k g_k(t) = \int_{-\infty}^{\infty} \chi(\tau) g(\tau,t) d\tau \\
	\Rightarrow \Phi{x(t)} & = \sum_k \chi_k \Phi\{g_k(t)\} = \int_{-\infty}^{\infty} \chi(\tau) \Phi\{g(\tau,t)\} d\tau
\end{align}
Using the definition of the Dirac delta function and applying our LTI (linear time-invariant) system
\begin{align}
	x(t) & =  \int_{-\infty}^{\infty} x(\tau) \delta(\tau-t) d\tau \\
	\Rightarrow 	\Phi\{x(t)\} & =  \int_{-\infty}^{\infty} x(\tau) \Phi\{\delta(\tau-t)\} d\tau = \int_{-\infty}^{\infty} x(\tau) h(\tau-t) d\tau = x(t) * h(t)
\end{align}
we find the system's output to be the convolution of the input wit its \emph{pulse response} or \emph{free induction decay (FID)} $h(t) = \Phi\{\delta(t)\}$. 
Furthermore, harmonics are eigenfunctions of LTI systems, and the \emph{frequency response} or \emph{spectrum} $H(\omega)$ is just the Fourier transform of the system's FID:
\begin{equation}
	\Phi\{e^{i\omega t}\} = \int_{-\infty}^{\infty} e^{i\omega t} h(\tau-t) d\tau =  e^{i\omega t} \int_{-\infty}^{\infty} e^{i\omega (\tau-t)} h(\tau-t) d\tau =  e^{i\omega t} \int_{-\infty}^{\infty} e^{i\omega (\tau)} h(\tau) d\tau = H(\omega) e^{i \omega t}
\end{equation}


%INSERT: x-y-component of FID

\subsection{Matrix formalism}

\subsubsection{Diagonizable matrices}
An $n \times n$ matrix $A$ is said to be diagonizable if there exists an invertible matrix $P$ such that
\begin{equation}
 P^{-1} A P = \begin{pmatrix} 
		\lambda_1 & & & \\
		& \lambda_2 & & \\
		& & \text{...} & \\
		& & & \lambda_n
              \end{pmatrix} = D
\end{equation}
If so, then 
\begin{equation}
 A P = P \begin{pmatrix} 
		\lambda_1 & & & \\
		& \lambda_2 & & \\
		& & \text{...} & \\
		& & & \lambda_n
              \end{pmatrix} = P D
\end{equation}
and by writing $P$ composed by its column vectors $P = ( \vec{\alpha}_1 \vec{\alpha}_2 ... \vec{\alpha}_n)$ we find for every $i = 1,2,...,n$
\begin{equation}
 A \vec{\alpha}_i = \lambda_i \vec{\alpha_i}
\end{equation}
Obviously $P$ is made up by the eigenvectors of $A$, while the entries of its diagonalized form $D$ are its eigenvalues. Furthermore, for an $n \times n$ matrix $A$ to possess exactly $n$ distintc eigenvalues is a sufficient condition for diagonalizabilty.

Diagonizable matrices are of interest because once diagonalized their powers can be computet in a very efficient manner:
\begin{align*}
 A^k & = (P D P^{-1})^k = ( P D P^{-1}) \cdot ( P D P^{-1}) \cdot ... \cdot (P D P^{-1}) \\
    & = P D (P^{-1} P) D (P^{-1} P) \cdot ... \cdot (P^{-1} P) D P^{-1} \\
    & = P D^k P^{-1}
\end{align*}
while the power of a diagonal matrix is just
\begin{equation}
 D^k = \begin{pmatrix} 
		\lambda_1 & & & \\
		& \lambda_2 & & \\
		& & \text{...} & \\
		& & & \lambda_n
              \end{pmatrix}^k = 
	\begin{pmatrix} 
		\lambda_1^k & & & \\
		& \lambda_2^k & & \\
		& & \text{...}^k & \\
		& & & \lambda_n^k
              \end{pmatrix}
\end{equation}
Also matrix exponentials can be computed in this way, since they can be expanded as power series such as below.
\end{comment}


\subsection{Essence}
The previous theoretical piece yields the following essential facts:
\begin{itemize}
  \item the spin interaction properties of a system consisting of $n$ spins including one electron and $n-1$ other nuclei can be described fully by one $3 \times 3$ g-tensor for the interaction linear in electron spin and a set of $n-1$ $3 \times 3$ A-tensors for the interactions between electron spin and each nucleus spin.
  \item the computation acts on the density matrix $\rho$ in Liouville space
  \item the density matrix $\rho$ may be propagated step-wise in time by applying the Liouvillian superoperator $\mathcal{L}$ repeatedly for short time steps in the manner of equation (\ref{eq-time-propagation})
  \item a spin system of $N$ states spans an $N^2$-dimensional Liouville space and an $N^4$-dimensional superoperator space
  \item the memory consumption of the simulation will be determined by the single isotropic part and the 25 anisotropic parts stemming from the $Q_{mm'}$ of the Liouvillian, which together scale with $26 \times N^4$.
  \item a spin simulation may be conducted entirely in the rotational frame
  \item the FID can be obtained by evaluating $\mathbf{J_+}$ on the propagated density matrix $\rho$
  \item the simulation has to be averaged over many orientations of a powder sample
\end{itemize}
A spin system consisting of an unpaired electron ($S=\tfrac{1}{2}$) and a nitrogen core ($S=1$) will yield $N = 2 \cdot 3 = 6$ possible states, a density matrix of $N^2 = 36$ elements, and a Liouvillian of $26 \cdot N^4=26 \cdot 1296 = 33,696$ elements. A Matlab complex double representation takes 16 bytes, yielding an estimate of $16 \cdot 26 \cdot N^4 \text{B} \approx 530 \text{kB}$ memory usage at maximum. If we add 4 protons ($S=\tfrac{1}{2})$ to the system, we have $N = 6 \cdot 2^4= 96$ states, $9216$ density matrix elements, $\sim \cdot 2.2 \cdot 10^{9}$ Liouvillian elements and a maximum memory usage of $33 \text{GB}$. In fact, the Matlab simulations take by far less memory, since all of the involved matrices are sparse. We will have a thorough memory benchmarking lateron.

\section{Parallelization of Spinach}

The Matlab library \emph{Spinach}\footnote{written by Theoretical Spin Dynamics Group, University of Southampton, \url{www.spindynamics.org}, for an architectural overview see \verb$docs/developer_notes/architecture_overview$} supplies efficient methods for large-scale spin dynamics simulations. It consists of the \emph{kernel} with implementations of general spin dynamics simulation techniques and the \emph{user-land} with a collection of different experiements to perform. Basically, the user prepares the description of a spin system, which is then translated by the kernel into basis set, Liouvillian superoperator, etc. The user-land decides how to deal with those objects, whether to apply a pre-established experiment, or whether to perform the kernel's simulation procedures manually. Though Spinach is able to simulate numerous kinds of experiments, in this work we are going to restrict ourselves to the standard $\tfrac{\pi}{2}$-pulsed EPR experiments, for which the user-land readily provides the method \verb|pulse_acquire|. 

\subsection{Spinach modification}
The implementation of a Spinach $\tfrac{\pi}{2}$-pulsed EPR simulation based on the theoretical concepts derived above is introduced in appendix (\ref{sec-spinach-computation}) and may be referred to for better understanding of the following. The key modifications done to parallelize the code may be found in appendix (\ref{sec-spinach-mod-code}).
\subsubsection{Implementation}
The simplemost form of parallelization applicable to Spinach will be to subdivide the amount of orientations into smaller packages and distribute them upon parallel tasks, depending on the number of nodes $n$ and the number of cores per node $p$ available. If we assume the restriction that MATLAB may only run parallel locally on one node, we may distribute a number $N$ of orientations as follows:
\begin{enumerate}
 \item Subdivide the orientations into $n$ packages of $N/n$ orientations each. If $n$ is not divisor of $N$, then every package gets $\lfloor N/n \rfloor$ orientations and the remaining orientations $N\ \text{mod}\ n$ are distributed equally over the first $N\ \text{mod}\ n$ packages.
 \item Evoke one MATLAB process on each node, hand them their orientation package and let them open a MATLAB pool with $p$ workers.
 \item { \begin{enumerate}
          \item Execute a \verb$parfor$-loop for each orientation in the package of $\lfloor N/n \rfloor$ or $\lfloor N/n \rfloor + 1$ orientations, in the following referred to as the ``parallel'' case. 
	  \item Just as above, subdivide the orientation package again into $p$ smaller packages for each core and distribute remaining orientations equally, then run a \verb$parfor$-loop $p$ times and let every core evaluate their package of orientations at once, in the following referred to as the ``mixed'' case, since it combines serial and parallel execution.
         \end{enumerate} }
\end{enumerate}

The two methods (a) and (b) of paralleization are both implemented. For case (a) we expect more communication between client and workers, but lower peak memory usage. For case (b) we expect to be able to reduce communication between client and workers and thereby safe time. Yet, since all orientations are propagated at once, we expect much higher peak memory usage. We are going to investigate this hypothesis lateron.

We will split the tasks performed by \verb$pulse_acquire(...)$ into three different functions, which are scheduled as distinct jobs and run subsequently, each one processing the they input data prepared by the previous:
\begin{itemize}
 \item \verb$function jlh_master_pulse_acquire(...)$ --- runs first, prepares the Liouvillian, and evokes several instances of... 
  \item \verb$function fid = jlh_outsourced_pulse_acquire(...)$ --- which run on each single node and do the actual propagation, producing every orientation package's FID.
  \item \verb$function jlh_sum_results(..)$ --- finally runs after all \verb$jlh_outsourced_pulse_acquire(...)$ have finished, collects their results, finalizes them and outputs the total FID.          
\end{itemize}
Furthermore we will make use of the helper functions
\begin{itemize}
 \item \verb$function job_scheduler = jlh_which_job_scheduler()$ --- determines the job scheduler equipped on the current platform and returns \verb$'TORQUE'$ or \verb$'SLURM'$. 
  \item \verb$function [job_identifier status stdout] = jlh_submit_job(... )$ --- submits a job executing command \verb$cmd$ via the platform's job scheduler.
  \item \verb$function [ pmem, walltime, queue ] = jlh_estimate_resources(...)$ --- a stub to be adapted to a specific cluster configuration. Shall be expanded to estimate the maximum CPU time and memory usage of a Spinach job depending on its parameters.
\end{itemize}

\subsection{Benchmarking}
There are three  major technical factors, which limit the scalabitlity of our parallelization:
\begin{enumerate}
 \item \underline{execution time} -- a simulation exceeding several days of runtime is not considered economical, in addition clusters usually limit the maximum execution time.
 \item \underline{memory} -- depending on the spin system's dimensions the Liouvillian grows exponentialy. When several orientations are propagated simultaneously, many copies of the Liouvillian may reside in a node's memory simultaneously, easily exceeding the cluster's hardware limitations.
  \item \underline{communication between threads} -- our parallelization relies on transferring the prepared Liouvillian in form of a local file, which might easily reach gigabyte dimensions. What is more, MATLAB internally limits the amount of data transferred to every \verb$parfor$-iteration. 
\end{enumerate}
Reducing the amount of simultaneously used memory by serialization means increasing the runtime and vice versa. More cores involved mean more memory occupied at the same time. In the following we want to examine how far we may exhaust those limitations and which of them will prove most restrictive. The following benchmarking has been performed on \emph{Soroban}\footnote{see appendix (\ref{sec-soroban}) for detailed technical information} and evaluates only \verb$jlh_outsourced_pulse_acquire(...)$ instances, thus not accounting for the resources required to build the Liouvillian.
 
\subsubsection{Single orientation}
To start with, we examine the scaling of Spinach for evaluating single orientations of 2- to 20-spin systems without involving any parallelization. We use the complete basis ESR-2 and the reduced basis ESR-1 and measure \underline{evaluation time}, \underline{peak virtual memory consumption}\footnote{virtual memory combines active RAM and inactive memory such as swap files} and \underline{file size} of the common input file storing the Liouvillian in dependence on the spin systems complexity. The semi-logarithmic graphs and their exponential fits in figure (\ref{fig-so-runtime}), (\ref{fig-so-memory}) and (\ref{fig-so-file-size}) clearly reflect exponential scaling in all three cases, except for deviations in very small systems. In those regimes technical side-effects may influence the scaling.

\begin{figure}
        \begin{subfigure}[b]{0.45\textwidth}
                \centering
                \includegraphics[width=\textwidth]{so-graphs/so_computation_time_fit.png}
                \caption{execution time in dependence on spin system complexity}
                \label{fig-so-runtime}
        \end{subfigure}
        ~ 
        \begin{subfigure}[b]{0.45\textwidth}
                \centering
                \includegraphics[width=\textwidth]{so-graphs/mem_usage_fit.png}
                \caption{peak virtual memory usage in dependence on spin system complexity}
                \label{fig-so-memory}
        \end{subfigure}
        \\
        \begin{subfigure}[b]{0.45\textwidth}
                \centering
                \includegraphics[width=\textwidth]{so-graphs/input_file_size.png}
                \caption{Liouvillian file size in dependence on spin system complexity}
                \label{fig-so-file-size}
        \end{subfigure}
	~ 
	\begin{subfigure}[b]{0.45\textwidth}
                \centering
                \includegraphics[width=\textwidth]{so-graphs/expansion.png}
                \caption{virtual memory usage in dependence on Liouvillian file size}
                \label{fig-so-expansion}
        \end{subfigure}
        \caption{Spinach execution statistics for one single orientation}
	\label{fig-so-stats}
\end{figure}

For the complete basis EPR-2 memory usage clearly is the limiting factor. While one orientation may be computed within minutes, the memory costs blow up into gigabytes and exceed Soroban's limit for a 12-spin system. The incomplete basis EPR-1 reaches such memory dimensions only for spin systems larger than 20. Consequently, we were able to benchmark spin systems up to size 11 for ESR-2 and up to size 20 for ESR-1. 

The Liouvillian's scaling determines the scaling of memory usage for a single orientation linearly, as may be found in graph (\ref{fig-so-expansion}). Both ESR-1 and ESR-2 case show the Liouvillian in file form expanding into a simulation of 20- to 22-fold size on a node's virtual memory.

\subsubsection{Single core computaion}
If only one core is available, the parfor-loop reduces to a serial for-loop in ``parallel'' mode, while the ``serial'' mode will propagate all orientations at one shot. Clearly, MATLAB's vector calculus optimization will somehow serialize the matrix calculations internally. In this section we will find out the resource usage of explicit serial calculation and of MATLAB matrix operations.

\subsubsection{Small scale spin systems}
\begin{figure}
        \begin{subfigure}[b]{0.45\textwidth}
                \centering
                \includegraphics[width=\textwidth]{2ppn-graphs/small_scale_runtime.png}
                \caption{two-core parallelization}
                \label{fig-2ppn-sc-runtime}
        \end{subfigure}
        ~ 
        \begin{subfigure}[b]{0.45\textwidth}
                \centering
                \includegraphics[width=\textwidth]{9ppn-graphs/small_scale_runtime.png}
                \caption{nine-core parallelization}
                \label{fig-9ppn-sc-memory}
        \end{subfigure}
	\caption{execution time in dependence on spin system complexity for small scale spin systems}
	\label{fig-sc-runtime}
\end{figure}

\begin{figure}
        \begin{subfigure}[b]{0.45\textwidth}
                \centering
                \includegraphics[width=\textwidth]{runtime-graphs/small_scale_runtime.png}
                \caption{two-core and nine-core parallelization runtime}
                \label{fig-total-sc-runtime}
        \end{subfigure}
        ~ 
        \begin{subfigure}[b]{0.45\textwidth}
                \centering
                \includegraphics[width=\textwidth]{runtime-graphs/parallel_mixed.png}
                \caption{runtime relation between mixed mode and parallel mode}
                \label{fig-parallel-mixed-runtime}
        \end{subfigure}
	\caption{}
	\label{fig-sc-runtime-2}
\end{figure}
The previous section leads to the conclusion that we are dealing with two different scaling regimes: For spin systems with less than seven spins, the ``mixed'' mode proves faster, whereas it does not bear any advantages, neither in runtime, nor in memory usage, for larger systems.

\subsubsection{Large scale spin systems}
From now on we examine the scaling behaviour for spin systems with more than six or seven spins in parallel mode. Technical side-effects diminish in comparison to the exponential scaling and by benchmarking simulations for several spin-core configurations we try to build a scaling model for large spin systems on Soroban and extrapolate it to even more complex spin systems to be able to predict whether and on what cluster configuration a certain large scale EPR simulation may run. 

\subsubsection{Scaling model}
Since the dimensions of the Liouvillian increase exponentially with the scale of the spin system $x$, we expect likewise exponential growth in runtime $r$ and memory requirements $m$ of form
\begin{equation}
 r_y(x), m_y(x) \propto a + b \cdot e^{\alpha x}
\end{equation}
Furthermore, we assume that CPU time is distributed equally among the cores $y$, such that
\begin{equation}
 r_x(y) \propto c + \frac{d}{y}
\end{equation}
whereas more cores $y$ will occupy more memory $m$ simultaneously, hence
\begin{equation}
 m_x(y) \propto c + d \cdot y
\end{equation}
Based on this background we will try to fit our benchmark results to the model
\begin{align}
 r(x,y)  & = \left( a_r + b_r \cdot e^{\alpha_r x} \right) \left(c_r + \frac{d_r}{y} \right) \\
 m(x,y)  & = \left( a_m + b_m \cdot e^{\alpha_m x} \right) \left(c_m + d_m \cdot y\right)
\end{align}




\section{Conclusion and outlook}

\section{Appendix}

\subsection{Clusters}
\label{sec-clusters}
Most supercomputers nowadays are so called \emph{clusters}: Many \emph{nodes} with several \emph{cores (CPUs)} each are connected via fast network. One single node's \emph{memory (RAM)} may be shared by all its cores, but every CPU usually has its own range of RAM, to which access is fastest. Access on another node's RAM via network is slowest. The advantage of computer clusters is obvious: hardware does not differ significantly from standard desktop computers, keeping purchase and maintainance costs reasonably low. 
The architecture of a cluster requires efficient resource management. For this purpose, several \emph{job scheduler} platforms exist. Everyone, who wishes to run a parrallel job on the cluster, has to \emph{submit} the job via the job scheduler. The job scheduler then asseses the job's potential resource usage upon the user's estimation and \emph{enqueues} the job with a certain priority for execution. Hence the user shall estimate well: Too generous estimations of memory usage and runtime will cause the job to be enqueued for days, too tight estimations though will cause the job to be terminated by the scheduler when it exceeds its claimed resources by far. 

Both clusters available for testing run on Linux, but they use different job schedulers. Here follows a short introduction of their features. 
\subsubsection{Sheldon}
\label{sec-sheldon}
Sheldon is a linux computer cluster of the Freie Universit\"at Berlin physics department and posseses nodes of different specifications, reaching from 68 eight core nodes with 2 to 4 GB RAM per core (n042-n109) over 32 twelve core nodes with 8GB RAM per core (n010-n041) up to two 32 core nodes with 2GB RAM per core (n110-n111)\footnote{see \url{https://wiki.physik.fu-berlin.de/it/doku.php?id=services:cluster:start} for detailed specifications}. A process running exclusively on one node can thus make use of 96GB RAM at maximum on the twelve core nodes. \emph{TORQUE Resource Manager}\footnote{maintained by \emph{Adaptive Computing}, \url{http://www.adaptivecomputing.com/products/open-source/torque/}} serves as Sheldon's job scheduler, and here is a summary of the most important commands:
\begin{itemize}
 \item \verb$qsub$ \emph{jobfile-name} -- submits a job for execution and returns a five digit job identifier
  \item \verb$showstart$ \emph{job-id} -- yields the expected start time of a certain job's execution
  \item \verb$qdel$ \emph{job-id} -- removes a certain job from the queue or aborts its execution
  \item \verb$qstat$ {\emph{job-id}} -- yields the status of all current jobs {or a certain job already submitted}
  \item \verb$qf$ -- displays the resource usage on all nodes of the whole cluster
\end{itemize}
A jobfile to evoke a matlab function will look like this:
\begin{lstlisting}
#!/bin/bash
#PBS -N testjob
#PBS -q batch
#PBS -l nodes=1:ppn=2
#PBS -l pmem=2gb
#PBS -l walltime=01:00:00
#PBS -m bea -M user@zedat.fu-berlin.de
#PBS -e testjob_torque_error
#PBS -o testjob_torque_output
#PBS -W depend=afterok:job-id1:job-id2:...

cd $PBS_O_WORKDIR
matlab -nodesktop -nosplash -r "generic_matlab_function(...); quit;" &> testjob_matlab.log
\end{lstlisting}
All \verb$#PBS$-lines are options to be read by TORQUE, they determine from top to bottom the job's name \verb$testjob$, the queue, the number of requested nodes and processors per node (ppn), the requested RAM per core, the maximum execution time, an email address to send status messages to, a filename for the error logfile, a filename for the standard output logfile, and a dependency list for jobs to be finished successfully before executing this job. Sheldon possesses two queues \verb$batch$ and \verb$highmem$, which enqueue for execution on the eight core nodes or on the twelve core nodes respectively. \verb#cd $PBS_O_WORKDIR# changes to the directory from which \verb$qsub$ was called, usually somewhere in the user's home directory. After \verb$testjob$ is finished, the TORQUE error and output can be found in this directory as \verb$testjob_torque_error.e$ and \verb$testjob_torque_output.o$, while Matlab's error and output will be located in \verb$testjob_matlab.log$.

For the time of writing Sheldon had a trial version of the MATLAB Distributed Computing Server available. Thus it was possible to conduct many-node parallel simulations there.

\subsubsection{Soroban}
\label{sec-soroban}
Soroban is a linux computer cluster of the Freie Universit\"at Berlin ZEDAT consisting of 112 nodes with twelve cores and 2GB RAM per core each\footnote{see \url{http://www.zedat.fu-berlin.de/Compute/Soroban} for detailed specifications}. A process running exclusively on one node can thus make use of 24GB RAM at maximum. SLURM\footnote{maintained by Lawrence Livermore National Laboratory 7000 East Avenue, Livermore, CA 94550, USA, \url{https://computing.llnl.gov/linux/slurm/slurm.html}} is Soroban's job scheduler, and here is a summary of its most important commands:
\begin{itemize}
 \item \verb$sbatch$ \emph{jobfile-name} -- submits a job for execution and returns a five digit job identifier
  \item \verb$scancel$ \emph{job-id} -- removes a certain job from the queue or aborts its execution
  \item \verb$squeue$ {\verb$-j$ \emph{job-id}} -- yields the status of all current jobs {or a certain job already submitted}
  \item \verb$sinfo$ or \verb$sview$-- display info on the resource usage on all nodes of the whole cluster, latter offers a GUI.
\end{itemize}
A jobfile to evoke a matlab function will look like this:
\begin{lstlisting}
 #!/bin/bash 
#SBATCH --job-name=testjob
#SBATCH --partition=main
#SBATCH --nodes=1 
#SBATCH --ntasks-per-node=2 
#SBATCH --mem-per-cpu=2GB
#SBATCH --mail-type=ALL
#SBATCH --mail-user=user@zedat.fu-berlin.de 
#SBATCH --error=testjob_slurm_error.e
#SBATCH --output=testjob_slurm_output.o 
#SBATCH --dependency=afterok:jod-id-1:job-id-2:...

cd $SUBMITDIR
module load matlab/R2011b
matlab -nodesktop -nosplash -r "generic_matlab_function(...); quit;" &> testjob_matlab.log                                                                                   
\end{lstlisting}
The meaning of all paramters goes in analogy with the TORQUE parameters described above. For Soroban it is not necessary to specify a certain queue, since the nodes do not differ much in hardware, but there still exist the queues (or ``partitions'') \verb$main$, \verb$test$ and \verb$gpu$.

On Soroban there are five MATLAB client licenses and two Parallel Computing Toolbox licenses available at the time of writing. Further restrictions apply: one MATLAB process can only open a MATLAB pool within one node with a maximum of INSERT workers. For our parallelization this means at most two multiple-core MATLAB processes with at most eight INSERT cores each, resulting a maximum of 16 parallel threads. 

\subsection{MATLAB on Clusters}
Code parallelization is highly platform dependeble, as argued in the previous section. What is more, the MATLAB environment imposes further constraints upon parallelization. Here we outline MATLAB concepts and their limitations.

%image source
%http://www.mathworks.com/support/product/DM/installation/images/interaction_new1.gif
\subsubsection{MATLAB licences}
\begin{figure}
  \centering
 \includegraphics[width=0.6\textwidth]{matlab-parallelization.jpg}
  \caption{The paralleization model of MATLAB}
  \label{fig-matlab-parallelization}
  \captionsetup{font={footnotesize,bf,it}}
  \caption*{source:  \url{http://www.mathworks.com/support/product/DM/installation/images/interaction_new1.gif}}
\end{figure}
MATLAB has a rather dedicated licence model, and for a parallelized computation several licenses are necessary:
\begin{itemize}
 \item A \emph{MATLAB client}, the standard MATLAB distribution to be checked out for the user's work station when starting MATLAB
\item A \emph{Parallel Computing Toolbox}, likewise to be checked out for the client to enable parallel code features
\item A \emph{Distributed Computing Server} on the cluster to open \emph{MATLAB workers} when requested by a client. The number of workers per node and per cluster is limited depending on the actual server licence.
\end{itemize}
The very idea of parallelization in Matlab visualized in figure (\ref{fig-matlab-parallelization}) then works as follows: A user wants to run parallel code in their MATLAB client. With the Parallel Computing Toolbox' command \verb$ matlabpool open$ \emph{poolsize} they may send a request to the cluster's Distributed Computing Server to allocate a number \emph{poolsize} of workers -- remote MATLAB processes without GUI. Granted that enough worker licences are available, the connection between client and cluster will be established and the user is then free to run their code. Afterwards he is to release the worker licences by calling \verb$ matlabpool close$.

This approach does not prove very handy in the case of our Spinach simulations for several reasons. Firstly, if the connection between client and cluster is lost, it is problematic to reconnect and receive any results from the ``workers without leader''. Secondly, in general work stations do not necessarily have the Parallel Computing Toolbox equipped. Thirdly, a smooth communication between Distributed Computing Server and job scheduler is required, which is rather fancy to configure. Hence we will ``work around'' the client-cluster problem by evoking a ``silent'' MATLAB client on one cluster node with minimal resource usage, which serves as a \emph{master process} by acting as the ``user within the cluster'', calling more MATLAB processes, opening the MATLAB pool and delegating tasks to the allocated workers automatically.

\subsubsection{Matlab - Linux interaction}
MATLAB offers one important command to evoke shell commands from within a MATLAB client:
\begin{lstlisting}
[status,stdout] = unix('any_command');
\end{lstlisting}
With its help it will be possible for us to create a function \verb$jlh_submit_job(...)$ submitting jobs on the cluster dynamically during MATLAB execution by calling \verb$qsub$ or \verb$sbatch$. Furthermore, we can extract the returned job identifier, track the job throughout its execution and create subsequent dependent jobs, all from within MATLAB. \verb$jlh_submit_job(...)$ can perform cluster-specific job submission by creating job-files such as mentioned above. Thereby we keep cluster-dependency away from Spinach. %\verb$jlh_submit_job(...)$ is discussed in appendix (\ref{sec-jlh-submit-job}).

One should notice that each MATLAB job executed directly via a jobfile checks out another MATLAB client and Parallel Computing Toolbox licence, while jobs indirectly scheduled via the \verb$matlabpool$ command stay inside one Parallel Computing Toolbox, but check out numerous worker licences. The aim will be to make maximum use of the available combination of client and worker licences.

\subsubsection{Parallel code elements}
The \emph{Parallel Computing Toolbox} offers several parallelization concepts, of which only the \verb$parfor$-loop will be important for us:
\begin{lstlisting}
parfor i=int_a:int_b
  ...code...
end
\end{lstlisting}

The parfor-loop just works like a normal for-loop, with the difference that single loop iterations are distributed to all workers of the current MATLAB pool. The loop iterations are then only executed on the workers, but not on the calling MATLAB client process. Consequently, the parfor-loop may not be applied to replace for-loops where the computation results depend on the ordered sequence of execution. Since we are only averaging over many orientations of an EPR powder sample, the parfor-loop may well be used in our case. 

Variables used inside a parfor-loop have to be initialized explicitely in the preceding code segment, in order to inform MATLAB about which workspace information to transfer to the workers. Furthermore, arrays indexed inside the parfor-body by the iteration variable \verb$i$ will be identified as ``sliced'' by MATLAB, and only the relevant parts of the array will be transferred to the worker. Those facts will turn out relevant lateron. % when loading variables into workspace from a file.

\subsection{A Spinach EPR Simulation}
\label{sec-spinach-computation}
%Cerf S.20
Using the theoretical basis introduced above, the procedure of an EPR simulation comes down to the following key steps:
\begin{enumerate}
 \item Spinach reads the g- and A-tensors from an input file and constructs the isotropic and anisotropic part of the Liouvillian in the rotational basis ...
 \item ... propagates the density matrix in one step through the $\tfrac{\pi}{2}$-pulse by applying a rotation operator ...
  \item ... then propagates the density matrix step by step through the relaxation process by applying the Liouville equation (\ref{eq-liouville}) repeatedly for short time steps, ...
 \item ... and determines the transversal magnetization depending on $\mathbf{J_+}$, a superposition of spin in x- and y-direction, for each step.
\end{enumerate}

In the following the preparation of input data and computation flow are summarized for a simple system consisting of an electron spin $\tfrac{1}{2}$, a nitrogen spin $1$ and a proton spin $\tfrac{1}{2}$.%, such that the idea where to implement parallelization becomes obvious.

\subsubsection{Typical input file}
\label{sec-input-file}
This Matlab file prepares a typical spin system and conducts a $\tfrac{\pi}{2}$-pulsed EPR experiment on it. The data structure \verb$sys$ contains information about the spin system and the experimental setup, \verb$inter$ represents the linear and bilinear interactions of the spins, \verb$bas$ specifies the basis set to be used and \verb$parameters$ specifies the enquired simulation results. 
\begin{lstlisting}
function jlh_3spins()

% Set the simulation parameters
sys.magnet=3.356;
sys.regime='powder';
bas.mode='ESR-1';
sys.tols.grid_rank=101;
\end{lstlisting} 
Specifies $B_0 = 3.356 T$ and tells Spinach to average the spectrum over uniformly distributed orientations in a ``powder''. The mode ``ESR-1'' generates a complete state space for all electrons, but reduces the state space for all nuclei in a certain way to be efficient enough and still yield reasonable EPR results. 
%INSERT description of state space reduction
The mode ``ESR-2'' will create a full state space for all electrons and anisptropically coupled nuclei, that is all nuclei in the case of our system. This would result in a $12$-dimensional state space, such that the density matrix stretched into a column vector will count $144$ elements, and the superoperators will be represented by $144\times144$ matrices. The grid rank $101$ chooses a certain Lebedev grid of $3470$ orientations to average about.
\begin{lstlisting}[firstnumber=last]
% Interactions
sys.isotopes={'E','14N', '1H'};
inter.zeeman.matrix=cell(3,1);
inter.zeeman.matrix{1,1}=[ 2.0056023 -0.0013775 -0.0004019; -0.0008185 2.0038816 0.0002087; -0.0002747 0.0001729 2.0062982];
inter.coupling.matrix=cell(3,3);
inter.coupling.matrix{1,2}=1e6*[29.4479  3.9997 -0.4979;   3.9997  76.1445 -14.8367;  -0.4979 -14.8367  38.4285];  %92.815191
inter.coupling.matrix{1,3}=1e6*[-1.2922  2.0819 -1.9943;  2.0819  -1.407 -1.7023; -1.9943 -1.7023 -1.5011];  %5.3217912
\end{lstlisting}
Advises Spinach to prepare a spin system of an unpaired electron, a nitrogen nucleus and a proton spin\footnote{for a full list of available standard isotopes have a look at \verb$kernel/spin.m$}. The Zeeman matrix represents the $3\times 3$ g-Tensor, while the coupling matrices represent the $3\times 3$ A-tensors accounting for the hyperfine interactions between electron spin and all other spins.
\begin{lstlisting}[firstnumber=last]
% Set the sequence parameters
parameters.offset=0;
parameters.sweep=1e9;
parameters.npoints=512;
parameters.zerofill=1024;
parameters.spins='E';
parameters.axis_units='Gauss';
parameters.derivative=0;
\end{lstlisting}
%Insert: Transmitter offset
Sets parameters for the experiment to simulate: \verb$npoints$ determines the number of time steps in the simulation, \verb$sweep$ chooses the spectral window's width, and thus the duration of one time step, \verb$zerofill$ sets the FID zero-filling and \verb$spins$ selects the spins to be pulsed and detected -- the electron spin in our case. \verb$derivative$ can be set to evaluate for the derivative of the FID instead.

\begin{lstlisting}[firstnumber=last]
% Run Spinach
spin_system=create(sys,inter);
spin_system=basis(spin_system,bas);
fid=pulse_acquire(spin_system,parameters);
\end{lstlisting}
The first kernel functions to be called are \verb$create(sys,inter)$ and \verb$basis(spin_system,bas)$. Former returns the data structure \verb$spin_system$, which describes  can be handed to the kernel lateron to reference to our spin system, e.g. to fetch the Liouvillian in question. A simplified sketch of \verb$spin_system$'s internal structure may be found in figure (insert). The values assigned to its different attributes by \verb$create$ and verb$basis$ for our specific sample spin system are added in bold font. Attributes directly determined by the parameters from this input file are marked red, attributes derived indirectly from those parameters are marked green.
 
\verb$pulse_acquire(spin_system, parameters)$ finally conducts the $\pi$-pulsed EPR and returns the time-resolved FID.
\begin{lstlisting}[firstnumber=last]
% Apodization
fid=apodization(fid,'crisp-1d');

% Perform Fourier transform
spectrum=fftshift(fft(fid,parameters.zerofill));

% ...

end
\end{lstlisting}
The ``crisp'' apodization modulates the FID by a declining cosine window function in the interval $[0,\tfrac{\pi}{2}]$
\begin{equation}
 \text{FID}'(t) = \text{FID}(t) \cdot \cos^8 \left( \frac{\pi}{2} \cdot \frac{t}{L_\text{FID}} \right)
\end{equation}
Line 31 finally performs Fast Fourier Transform to generate the frequency domain spectrum.

%Insert graphics about the effect of fft, zero filling and shifting

\subsubsection{pulse\_acquire}
\label{sec-pulse-acquire}

\begin{lstlisting}
function fid=pulse_acquire(spin_system,parameters,L,rho)

%...

% Compute the digitization parameters.
timestep=1/parameters.sweep;

% Generate the basic operators
Lp=operator(spin_system,'L+',parameters.spins);
Ly=(Lp-Lp')/2i;
\end{lstlisting}
The function \verb$operator$ prepares the raising superoperator $J_+$ and then constructs
\begin{equation}
  J_y = \frac{1}{2i} ( J_+ - J_- ) = \frac{1}{2i} ( J_+ - J_+^\dagger )
\end{equation}
The apostrophe in the Matlab code marks the complex conjugate transposition $J_+^\dagger$ of $J_+$. The relation above can be easily found by realizing that the raising and the lowering operator form a Hermitian conjugate pair $J_- = J_+^\dagger$
%\begin{align}
% L_+ = L_x + i L_y, \quad L_+^\dagger = L_x^\dagger - i L_y^\dagger \\
%  \frac{L_+ - L_+^\dagger}{2i} = \frac{L_y + L_y\dagger}{2}
%\end{align}

\begin{lstlisting}[firstnumber=last]
% Set the secularity assumptions
spin_system=secularity(spin_system,'nmr');

% Start from thermal equilibrium
rho=equilibrium(spin_system);
\end{lstlisting}
The \verb$secularity$ function decides about the importance of interactions. In high field EPR and NMR, only the electrons' states are accounted for fully, whereas the nuclei's spins are only evaluated in z-direction. Density matrix \verb$rho$ is initialized with the termal equilibrium state of the spin system.

\begin{lstlisting}[firstnumber=last]
[Iso,Q]=h_superop(spin_system);
\end{lstlisting}

The isotropic part of the Liouvillian superoperator is stored in the $144\times144$ matrix \verb$Iso$, while \verb$Q$ is the set of 25 $Q_{mm'}$ rotational basis operators stored in a $5\times5$ matrix of $144\times144$ matrices representing the Liouvillian's anisotropic part. The dimensions of those two matrices determine Spinach's memory consumption.

\begin{lstlisting}[firstnumber=last]
% Get the spherical averaging grid
grid=load([spin_system.sys.root_dir spin_system.sys.slash 'exp' ...
				    spin_system.sys.slash 'grids' ...
				    spin_system.sys.slash 'lebedev_rank_' num2str(spin_system.tols.grid_rank) '.dat'],'ASCII');
grid_size=size(grid,1); phi=pi*grid(:,1)/180; theta=pi*grid(:,2)/180; weight=grid(:,3);
\end{lstlisting}
The Lebedev grid is read from a file holding all precomputed orientations on the unit sphere. The number of points for a Lebedev grid of certain rank can be found in table (\ref{tab-lebedev}).

\begin{lstlisting}[firstnumber=last]
% Get the orientation array
L_aniso=orientation(Q,[phi theta zeros(size(theta))]);
L=blkdiag(L_aniso{:})+kron(speye(grid_size),Iso);
L=clean_up(spin_system,L,spin_system.tols.liouv_zero);
\end{lstlisting}
\verb$orientation$ rotates the anisotropic part of the Liouvillian in the rotational basis by the specified Euler angles and creates a cell array of operators, one for each orientation. The Liouvillian block matrix \verb$L$ has a diagonal element for every Lebedev orientation $n$:
\begin{equation}
 L= L_{\text{aniso}} + I \otimes L_\text{iso} =
	      \begin{pmatrix} 
		L_{\text{aniso},1} & & & \\
		& L_{\text{aniso},2} & & \\
		& & \text{...} & \\
		& & & L_{\text{aniso},n}
              \end{pmatrix} +
	      \begin{pmatrix} 
		1 & & & \\
		& 1 & & \\
		& & \text{...} & \\
		& & & 1
              \end{pmatrix} \otimes L_\text{iso}
\end{equation}

\begin{lstlisting}[firstnumber=last]
% Get the initial and the detection states
rho=kron(ones(grid_size,1),rho);
coil=kron(weight,state(spin_system,'L+',parameters.spins));
\end{lstlisting}
The density matrix is duplicated $n$ times in a column vector to propagate one for each orientation, and similarly the observable to be detected is duplicated \underline{and the Lebedev weights are applied} in a column vector \verb$coil$. In the experimental setup the detection coil measures independently the magnetization in x- and y-direction, which correspond to the horizontal spin state $J_+ = J_x + i J_y$, \verb$'L+'$ in Spinach notation.

\begin{lstlisting}[firstnumber=last]
% Apply the pulse
rho=step(spin_system,kron(speye(grid_size),Ly),rho,pi/2);

fid=evolution(spin_system,L,coil,rho,timestep,parameters.npoints-1,'observable');

end
\end{lstlisting}
Generally, \verb$step(spin_system,L,rho,dt)$ propagates the density matrix \verb$rho$ under the influence of a certain Liouvillian \verb$L$ by a time step \verb$dt$. Because \verb$step$ makes uses of the evolution superoperator (\ref{eq-evolution}) internally, it can conduct a $90^\circ$ rotation around the y-axis by replacing the time step by an angle $\tfrac{\pi}{2}$ and the Liouvillian by the spin superoperator $J_y$, letting it construct the rotation operator
\begin{equation}
 R_y (\tfrac{\pi}{2}) = e^{-i \tfrac{\pi}{2} J_y}
\end{equation}
in analogy to equation (\ref{eq-z-rotation}). This just rotates all spins into the x-y-plane, just as a $\tfrac{\pi}{2}$-pulse will do. 
Sequently, \verb$evolution$ can be regarded as a sequence of \verb$npoints$ \verb$step$-functions propagating the density matrix through the whole time interval by steps of duration \verb$timestep$ by applying the Liouvillian \verb$L$. In addition, the observable \verb$coil$ is evaluated for every single step, recording the time resolved FID with magnetization in x-direction as its real part and magnetization in y-direction as its imaginary part. 

\subsection{Spinach modification code}
\label{sec-spinach-mod-code}

\subsubsection{Master process}
The enhanced call
\begin{lstlisting}
function jlh_master_pulse_acquire(spin_system,parameters,L,rho)
\end{lstlisting}
compared with the original call
\begin{lstlisting}
function fid=pulse_acquire(spin_system,parameters,L,rho)
\end{lstlisting}
does not return any results. Hence it should be the last call in the input file\footnote{discussed in appendix (\ref{sec-input-file})}. In addition to the standard parameters it expects \verb$parameters.nodes$ and \verb$parameters.ppn$ to decide how many nodes and cores to distribute the orientations onto. \verb$jlh_master_pulse_acquire$ constructs the rotational basis set and the Liouvillian in the rotational basis by standard Spinach means, writes a file \verb$input_file_name$ 
\begin{lstlisting}
save(input_file_name, 'spin_system','Iso', 'Q', 'Ly', 'rho', 'phi', 'theta', 'weight',...);
\end{lstlisting}
where the stored information includes
\begin{itemize}
 \item \verb$Iso$ and \verb$Q$ --- the isotropic and anisotropic Liouvillian,
  \item \verb$Ly$ --- the rotation operator to tilt the spins around the y-axis,
  \item \verb$rho$ --- the density matrix in equilibrium,
  \item \verb$phi$, \verb$theta$ and \verb$weight$ --- the orientations and weights of the chosen Lebedev grid,
  \item ... and further technical parameters,
\end{itemize}
then uses \verb$jlh_submit_job(...)$ repeatetly to create $n$ instances of \texttt{jlh\_outsourced\_pulse\_acquire(...)}, which all read their data from the same input file \verb$input_file_name$, but write there output to instance-specific output files. Since different orientations apparently take differing time intervals to be treated, the orientation packages are assembled such that every package contains only every $n$'th orientation, starting with offsets from $1,2,...$ to $n$. Thereby a better spatial distribution of the orientations among the packages is guaranteed.

Eventually, one instance of \verb$jlh_sum_results(...)$ is queued to run after the successful execution of all \texttt{jlh\_outsourced\_pulse\_acquire(...)} instances, collecting and adding up all parial FIDs.

\subsubsection{Child processes}
The essence of the simulation is packed in
\begin{lstlisting}
function fid=jlh_outsourced_pulse_acquire(orientation_start, orientation_step, orientation_end, input_file_name, output_file_name)
    orientations = orientation_start:orientation_step:orientation_end;
    orientation_count = length(orientations);
\end{lstlisting}
which is able to calculate the accumulated FID over an arbitrary range of orientations specified by its parameters \verb$orientation_start$, \verb$orientation_step$ and \verb$orientation_end$. 

When loading the Liouvillian and other data from the .mat file prepared by \verb$jlh_master_pulse_acquire$ we have to initialize the variables explicitly to make them available inside a parfor-body
\begin{lstlisting}
tmp = load(input_file_name);
spin_system = tmp.spin_system;
Iso = tmp.Iso;
Q = tmp.Q;
Ly = tmp.Ly;
rho = tmp.rho;
phi = tmp.phi;
theta = tmp.theta;
weight = tmp.weight;
\end{lstlisting}

The function offers ``parallel'', ``mixed'' and ``serial'' mode. In parallel mode, the orientations are treated according to case (a) of above's enumeration: 
\begin{lstlisting}
% Get the detection state            
coil = state(spin_system,'L+',parameters.spins);

parfor i=1:orientation_count
    n = orientations(i);

    % Get the current orientation
    L=Iso+orientation(Q,[phi(n) theta(n) 0]);

    % Apply the pulse
    rho_pulsed=step(spin_system,Ly,rho,pi/2);

    % Run the simulation
    fid=fid+weight(n)*evolution(spin_system,L,coil,rho_pulsed,1/parameters.sweep,parameters.npoints-1,'observable'); 
end
\end{lstlisting}
For every orientation in the package the parfor-body is executed ones, causing MATLAB to distribute the parfor-iterations among the available cores and applying the evolution operator once to every single orientation.

In mixed mode, the orientations are treated according to case (b):
\begin{lstlisting}
phi_set = cell(1,parameters.ppn);
theta_set = cell(1,parameters.ppn);
weight_set = cell(1,parameters.ppn);

for i=1:parameters.ppn
    set = orientations(i:parameters.ppn:orientation_count);
    phi_set{i} = phi(set);
    theta_set{i} = theta(set);
    weight_set{i} = weight(set); 
end

parfor i=1:parameters.ppn
    L_aniso=orientation(Q,[phi_set{i} theta_set{i} zeros(size(theta_set{i}))]);
    L=blkdiag(L_aniso{:})+kron(speye(length(theta_set{i})),Iso);
    L=clean_up(spin_system,L,spin_system.tols.liouv_zero);

    % Get the initial and the detection states
    current_rho=kron(ones(length(theta_set{i}),1),rho);
    current_coil=kron(weight_set{i},state(spin_system,'L+',parameters.spins));

    % Apply the pulse
    current_rho=step(spin_system,kron(speye(length(theta_set{i})),Ly),current_rho,pi/2);
    
    fid=fid+evolution(spin_system,L,current_coil,current_rho,1/parameters.sweep,parameters.npoints-1,'observable');
end
\end{lstlisting}
First of all, again smaller sets of orientations are ``sliced'' into the cell arrays \verb$phi_set$, \verb$theta_set$ and \verb$weight_set$. Since the packages can differ in length, we use cell arrays to allow for differing dimensions in each column. Then, very much like the standard serial computation\footnote{discussed in appendix (\ref{sec-pulse-acquire})}, each orientation package is propagated at once in one parfor-iteration. Since we have exactly $p$ iterations, every available core will evaluate one parfor-body and hence propagate one subset of orientations. 

The serial mode treats all orientations at once locally.

Eventually the FID is written to an instance-specific output file.

\subsubsection{Finalization process}
Reads every single output file listed in \verb$output_file_name$, adds up the partial FIDs and performs all finalization tasks like apodization and Fourier transform originally done in the end of the Spinach input file\footnote{discussed in appendix (\ref{sec-input-file})}.

\begin{lstlisting}
function jlh_sum_results(input_file_name)
    load(input_file_name,'spin_system','parameters','output_file_name','spectrum_file_name', 'debug_file_name');

    %preallocating fid array
    fid=zeros(parameters.npoints,1);
    
    for i=1:parameters.nodes
        %checking, whether each process wrote ouput file correctly
        if exist(output_file_name{i}, 'file')
            tmp = load( output_file_name{i}, 'fid');
            fid = fid + tmp.fid;
        else
           %reporting errror otherwise
           report(spin_system, [sprintf('jlh_sum_results: Error: jlh_outsourced_pulse_acquire instance %d did not write output file "', i) output_file_name{i} '"!']);
        end
    end   

    % Apodization
    fid=apodization(fid,'crisp-1d');

    % Perform Fourier transform
    spectrum=fftshift(fft(fid,parameters.zerofill));

    %Compute the derivative if necessary
    if isfield(parameters,'derivative')
        spectrum=fft(ifft(spectrum).*fftdiff(parameters.derivative,length(spectrum),1)');
    end

    ax=axis_1d(spin_system,parameters);
    data = cat(2, transpose(ax), real(spectrum));
    save(spectrum_file_name,'data', '-ASCII');
end
\end{lstlisting}


\subsection{Figures}

\begin{figure}
  \centering
 \includegraphics[width=0.6\textwidth]{spin_system_simplified.jpg}
  \caption{The Spinach spin-system data structure filled with attributes of an electron-nitrogen-proton spin system.}
  \captionsetup{font={footnotesize,bf,it}}
  \caption*{edited extract from \url{http://spindynamics.org/documents/spinach_1.2.1217.zip}}
\end{figure}


\FloatBarrier
\begin{thebibliography}{9}
\bibitem{spindyn}
  Dr. Ilya Kuprov,
  \emph{Spin Dynamics, Lecture 1 - 17}.
  University of Oxford,
  2011.

\bibitem{spinach}
  H.J. Hogben, M. Krzystyniak, G.T.P. Charnock, P.J. Hore, Ilya Kuprov,
  \emph{Spinach - A software library for simulation of spin dynamics in large spin systems}.
  Journal of Magnetic Resonance,
  208 (2011) 179-194.

\bibitem{spinach-input-manual}
  Theoretical Spin Dynamics Group, \url{www.spindynamics.org}, 
  \emph{Spinach package - input preparation manual}.
  University of Southampton, 
  2011.

\bibitem{cerf}
  Corinne Cerf,
  \emph{NMR Spectroscopy: From Quantum Mechanics to Protein Spectra}.
  %Unit\'e de Conformation des Macromol\'ecules Biologiques, 
  Concepts in Magnetic Resonancem Vol. 9(1) 17-41, (1997)

\bibitem{lebedev}
  Baltzar Stevensson, Mattias Ed\'en,
  \emph{Efficient orientational averaging by the extension of Lebedev grids via regularized octahedral symmetry expansion}.
  Journal of Magnetic Resonance,
  191 (2006) 162-176.

\bibitem{griffiths}
  David J. Griffiths,
  \emph{Introduction to Quantum Mechanics}.
  Pearson, 
  2nd Edition, 
  2005.

\bibitem{nmr-ox}
  Paul T. Callaghan,
  \emph{Translational Dynamics \& Magnetic Resonance. Principles of Pulsed Gradient Spin Echo NMR}.
  Oxford University Press,
  2011.

\bibitem{slichter}
  Charles P. Slichter
  \emph{Principles of Magnetic Resonance}
  Springer,
  3rd Enlarged and Updated Edition, Corrected 3rd Printing,
  1996.

\end{thebibliography}

\end{document}